{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Verification Notebook\n",
    "\n",
    "Verify data collected from API and uploaded to Hugging Face.\n",
    "\n",
    "**Checks:**\n",
    "1. Available leagues and seasons\n",
    "2. Match counts and completeness\n",
    "3. Data quality (missing values, duplicates)\n",
    "4. Supporting data (events, lineups, player_stats)\n",
    "5. Feature engineering readiness"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_DIR = Path('../data/01-raw')\n",
    "EXPECTED_MATCHES_PER_SEASON = 380  # Premier League\n",
    "\n",
    "print(f'Data directory: {DATA_DIR.absolute()}')\n",
    "print(f'Exists: {DATA_DIR.exists()}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview: Available Leagues and Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_overview(data_dir: Path) -> pd.DataFrame:\n",
    "    \"\"\"Get overview of all available data.\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for league_dir in sorted(data_dir.iterdir()):\n",
    "        if not league_dir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        for season_dir in sorted(league_dir.iterdir()):\n",
    "            if not season_dir.is_dir():\n",
    "                continue\n",
    "            \n",
    "            matches_file = season_dir / 'matches.parquet'\n",
    "            if not matches_file.exists():\n",
    "                continue\n",
    "            \n",
    "            df = pd.read_parquet(matches_file)\n",
    "            \n",
    "            # Count completed matches\n",
    "            status_col = 'fixture.status.short'\n",
    "            if status_col in df.columns:\n",
    "                completed = len(df[df[status_col].isin(['FT', 'AET', 'PEN'])])\n",
    "            else:\n",
    "                completed = len(df)\n",
    "            \n",
    "            # Check supporting files\n",
    "            has_events = (season_dir / 'events.parquet').exists()\n",
    "            has_lineups = (season_dir / 'lineups.parquet').exists()\n",
    "            has_stats = (season_dir / 'player_stats.parquet').exists()\n",
    "            \n",
    "            rows.append({\n",
    "                'League': league_dir.name,\n",
    "                'Season': season_dir.name,\n",
    "                'Total Matches': len(df),\n",
    "                'Completed': completed,\n",
    "                'Completeness': f'{completed/EXPECTED_MATCHES_PER_SEASON*100:.1f}%',\n",
    "                'Events': 'Yes' if has_events else 'No',\n",
    "                'Lineups': 'Yes' if has_lineups else 'No',\n",
    "                'Stats': 'Yes' if has_stats else 'No'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "overview = get_data_overview(DATA_DIR)\n",
    "print(f'Total: {len(overview)} season(s) across {overview[\"League\"].nunique()} league(s)')\n",
    "print(f'Total matches: {overview[\"Total Matches\"].sum():,}')\n",
    "print()\n",
    "display(overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detailed Match Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_matches(league: str, season: str) -> dict:\n",
    "    \"\"\"Analyze match data quality for a specific season.\"\"\"\n",
    "    path = DATA_DIR / league / season / 'matches.parquet'\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_parquet(path)\n",
    "    \n",
    "    is_raw_api = 'fixture.id' in df.columns\n",
    "    \n",
    "    if is_raw_api:\n",
    "        id_col = 'fixture.id'\n",
    "        date_col = 'fixture.date'\n",
    "        home_col = 'teams.home.name'\n",
    "        away_col = 'teams.away.name'\n",
    "        home_goals = 'goals.home'\n",
    "        away_goals = 'goals.away'\n",
    "        status_col = 'fixture.status.short'\n",
    "    else:\n",
    "        id_col = 'fixture_id'\n",
    "        date_col = 'date'\n",
    "        home_col = 'home_team_name'\n",
    "        away_col = 'away_team_name'\n",
    "        home_goals = 'ft_home'\n",
    "        away_goals = 'ft_away'\n",
    "        status_col = 'status'\n",
    "    \n",
    "    result = {\n",
    "        'total_matches': len(df),\n",
    "        'columns': len(df.columns),\n",
    "        'format': 'Raw API' if is_raw_api else 'Clean',\n",
    "        'unique_fixtures': df[id_col].nunique() if id_col in df.columns else 'N/A',\n",
    "        'duplicates': len(df) - df[id_col].nunique() if id_col in df.columns else 0,\n",
    "    }\n",
    "    \n",
    "    if status_col in df.columns:\n",
    "        result['status_breakdown'] = df[status_col].value_counts().to_dict()\n",
    "        result['completed'] = len(df[df[status_col].isin(['FT', 'AET', 'PEN'])])\n",
    "    \n",
    "    if date_col in df.columns:\n",
    "        dates = pd.to_datetime(df[date_col])\n",
    "        result['date_range'] = f\"{dates.min().strftime('%Y-%m-%d')} to {dates.max().strftime('%Y-%m-%d')}\"\n",
    "    \n",
    "    if home_col in df.columns and away_col in df.columns:\n",
    "        all_teams = set(df[home_col].unique()) | set(df[away_col].unique())\n",
    "        result['unique_teams'] = len(all_teams)\n",
    "        result['teams'] = sorted(all_teams)\n",
    "    \n",
    "    # Goals\n",
    "    if home_goals in df.columns and away_goals in df.columns:\n",
    "        df_completed = df[df[status_col].isin(['FT', 'AET', 'PEN'])] if status_col in df.columns else df\n",
    "        result['avg_home_goals'] = df_completed[home_goals].mean()\n",
    "        result['avg_away_goals'] = df_completed[away_goals].mean()\n",
    "        result['avg_total_goals'] = (df_completed[home_goals] + df_completed[away_goals]).mean()\n",
    "        result['missing_scores'] = df_completed[[home_goals, away_goals]].isna().any(axis=1).sum()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Analyze all seasons\n",
    "for _, row in overview.iterrows():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{row['League']} - Season {row['Season']}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    analysis = analyze_matches(row['League'], row['Season'])\n",
    "    if analysis:\n",
    "        print(f\"Total matches: {analysis['total_matches']}\")\n",
    "        print(f\"Completed: {analysis.get('completed', 'N/A')}\")\n",
    "        print(f\"Format: {analysis['format']}\")\n",
    "        print(f\"Duplicates: {analysis['duplicates']}\")\n",
    "        print(f\"Date range: {analysis.get('date_range', 'N/A')}\")\n",
    "        print(f\"Teams: {analysis.get('unique_teams', 'N/A')}\")\n",
    "        if 'avg_total_goals' in analysis:\n",
    "            print(f\"Avg goals/match: {analysis['avg_total_goals']:.2f}\")\n",
    "        if 'status_breakdown' in analysis:\n",
    "            print(f\"Status: {analysis['status_breakdown']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Supporting Data Quality (Events, Lineups, Player Stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_supporting_data(league: str, season: str) -> dict:\n",
    "    \"\"\"Analyze supporting data files.\"\"\"\n",
    "    base_dir = DATA_DIR / league / season\n",
    "    result = {}\n",
    "    \n",
    "    # Events\n",
    "    events_path = base_dir / 'events.parquet'\n",
    "    if events_path.exists():\n",
    "        events = pd.read_parquet(events_path)\n",
    "        result['events'] = {\n",
    "            'rows': len(events),\n",
    "            'columns': list(events.columns)\n",
    "        }\n",
    "    \n",
    "    # Lineups\n",
    "    lineups_path = base_dir / 'lineups.parquet'\n",
    "    if lineups_path.exists():\n",
    "        lineups = pd.read_parquet(lineups_path)\n",
    "        result['lineups'] = {\n",
    "            'rows': len(lineups),\n",
    "            'columns': list(lineups.columns)\n",
    "        }\n",
    "    \n",
    "    # Player stats\n",
    "    stats_path = base_dir / 'player_stats.parquet'\n",
    "    if stats_path.exists():\n",
    "        stats = pd.read_parquet(stats_path)\n",
    "        result['player_stats'] = {\n",
    "            'rows': len(stats),\n",
    "            'columns': list(stats.columns)\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Show supporting data for first available season\n",
    "if len(overview) > 0:\n",
    "    sample = overview.iloc[0]\n",
    "    print(f\"Supporting data sample: {sample['League']} {sample['Season']}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    support = analyze_supporting_data(sample['League'], sample['Season'])\n",
    "    for name, info in support.items():\n",
    "        print(f\"\\n{name.upper()}:\")\n",
    "        print(f\"  Rows: {info['rows']}\")\n",
    "        print(f\"  Columns: {info['columns']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sample Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_matches(league: str, season: str, n: int = 5):\n",
    "    \"\"\"Show sample matches from a season.\"\"\"\n",
    "    path = DATA_DIR / league / season / 'matches.parquet'\n",
    "    if not path.exists():\n",
    "        print(f\"No data for {league}/{season}\")\n",
    "        return\n",
    "    \n",
    "    df = pd.read_parquet(path)\n",
    "    \n",
    "    # Select display columns based on format\n",
    "    if 'fixture.id' in df.columns:\n",
    "        cols = ['fixture.id', 'fixture.date', 'teams.home.name', 'teams.away.name', \n",
    "                'goals.home', 'goals.away', 'fixture.status.short']\n",
    "    else:\n",
    "        cols = ['fixture_id', 'date', 'home_team_name', 'away_team_name', \n",
    "                'ft_home', 'ft_away', 'status']\n",
    "    \n",
    "    available_cols = [c for c in cols if c in df.columns]\n",
    "    \n",
    "    print(f\"\\nLast {n} matches from {league} {season}:\")\n",
    "    display(df[available_cols].tail(n))\n",
    "\n",
    "# Show samples for each season\n",
    "for _, row in overview.iterrows():\n",
    "    show_sample_matches(row['League'], row['Season'], n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quality_report(overview_df: pd.DataFrame) -> None:\n",
    "    \"\"\"Generate overall data quality report.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DATA QUALITY SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    total_matches = overview_df['Total Matches'].sum()\n",
    "    total_completed = overview_df['Completed'].sum()\n",
    "    \n",
    "    print(f\"\\nTotal seasons: {len(overview_df)}\")\n",
    "    print(f\"Total matches: {total_matches:,}\")\n",
    "    print(f\"Total completed: {total_completed:,}\")\n",
    "    print(f\"Overall completion: {total_completed/total_matches*100:.1f}%\")\n",
    "    \n",
    "    # Check for issues\n",
    "    issues = []\n",
    "    \n",
    "    for _, row in overview_df.iterrows():\n",
    "        if row['Completed'] < EXPECTED_MATCHES_PER_SEASON * 0.9:\n",
    "            if row['Season'] != '2025':  # Current season expected to be incomplete\n",
    "                issues.append(f\"{row['League']} {row['Season']}: Only {row['Completed']} completed matches\")\n",
    "        \n",
    "        if row['Events'] == 'No':\n",
    "            issues.append(f\"{row['League']} {row['Season']}: Missing events data\")\n",
    "        if row['Lineups'] == 'No':\n",
    "            issues.append(f\"{row['League']} {row['Season']}: Missing lineups data\")\n",
    "        if row['Stats'] == 'No':\n",
    "            issues.append(f\"{row['League']} {row['Season']}: Missing player stats data\")\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"\\nPotential issues ({len(issues)}):\")\n",
    "        for issue in issues:\n",
    "            print(f\"  - {issue}\")\n",
    "    else:\n",
    "        print(\"\\nNo issues detected!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "generate_quality_report(overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, str(Path('..').absolute()))\n",
    "\n",
    "from src.features.cleaners import MatchDataCleaner\n",
    "from src.features.engineers import TeamFormFeatureEngineer, MatchOutcomeFeatureEngineer\n",
    "\n",
    "def test_feature_engineering(league: str, season: str):\n",
    "    \"\"\"Test if feature engineering works on the data.\"\"\"\n",
    "    path = DATA_DIR / league / season / 'matches.parquet'\n",
    "    if not path.exists():\n",
    "        return False, \"Data not found\"\n",
    "    \n",
    "    try:\n",
    "        # Load and clean\n",
    "        df = pd.read_parquet(path)\n",
    "        cleaner = MatchDataCleaner()\n",
    "        cleaned = cleaner.clean(df)\n",
    "        \n",
    "        # Create features\n",
    "        data = {'matches': cleaned}\n",
    "        \n",
    "        form_eng = TeamFormFeatureEngineer(n_matches=5)\n",
    "        form_features = form_eng.create_features(data)\n",
    "        \n",
    "        outcome_eng = MatchOutcomeFeatureEngineer()\n",
    "        outcome_features = outcome_eng.create_features(data)\n",
    "        \n",
    "        return True, {\n",
    "            'cleaned_rows': len(cleaned),\n",
    "            'form_features': list(form_features.columns),\n",
    "            'outcome_features': list(outcome_features.columns)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "print(\"Testing feature engineering on each season...\\n\")\n",
    "for _, row in overview.iterrows():\n",
    "    success, result = test_feature_engineering(row['League'], row['Season'])\n",
    "    status = 'PASS' if success else 'FAIL'\n",
    "    print(f\"{row['League']} {row['Season']}: {status}\")\n",
    "    if not success:\n",
    "        print(f\"  Error: {result}\")\n",
    "    else:\n",
    "        print(f\"  Cleaned rows: {result['cleaned_rows']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare with Hugging Face (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to download and compare with HF data\n",
    "# This requires huggingface_hub to be installed\n",
    "\n",
    "# from huggingface_hub import HfApi\n",
    "# \n",
    "# api = HfApi()\n",
    "# repo_id = \"your-username/your-repo\"  # Update with your repo\n",
    "# \n",
    "# files = api.list_repo_files(repo_id)\n",
    "# print(f\"Files in HF repo: {len(files)}\")\n",
    "# for f in files:\n",
    "#     print(f\"  {f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
