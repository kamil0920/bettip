uv run python3 code/datascripts/fetch_backfill_pro.py --seasons 2025 2022 2022 2022 2020 2020 --include-players --include-injuries --concurrency 10

for s in 2025 2024 2023 2022 2021 2020; do   uv run python3 code/datascripts/normalization/normalize_season.py --season $s; done


If you want to upgrade all dependencies to their latest compatible versions during this step, add --upgrade:
uv lock --upgrade

----> source my-ml-env/bin/activate

Apply the lockfile to your project's virtual environment (installing or updating packages in .venv):
uv sync




Compare normalized matches to the fixtures_list (identify missing fixture IDs)

uv run python3 - <<'PY'
import pandas as pd
fl = pd.read_parquet('data/seasons/2019/fixtures_list_2019.parquet')   # raw list from API
m  = pd.read_parquet('data/seasons/2019/matches.parquet')             # normalized matches
print("fixtures_list count:", len(fl))
print("matches count:", len(m), "unique fixture_ids:", m['fixture_id'].nunique())

# columns vary by schema — adjust col name if different:
fl_ids = set(fl['fixture.id'].dropna().astype(int).tolist())
m_ids  = set(m['fixture_id'].dropna().astype(int).tolist())
missing = sorted(list(fl_ids - m_ids))
print("Missing fixtures:", len(missing))
print("Sample missing fixture ids (first 20):", missing[:20])
PY



Re-merge batches (force rebuild merged file) — only if you find missing rows / batch read errors:

# Run from repo root (this re-writes fixtures_detailed_all_2025.parquet)
uv run python3 - <<'PY'
import pandas as pd
from pathlib import Path
p = Path("data/seasons/2024")
batches = sorted(p.glob("fixtures_detailed_batch_*.parquet"))
dfs=[]
for f in batches:
    try:
        dfs.append(pd.read_parquet(f))
    except Exception as e:
        print("batch read error", f.name, e)
if not dfs:
    print("No good batch files to merge")
else:
    df_all = pd.concat(dfs, ignore_index=True)
    df_all.to_parquet(p/'fixtures_detailed_all_2025.parquet', index=False)
    print("Wrote merged rows:", len(df_all))
PY




Map missing fixture IDs to batch numbers & check batch file row counts
Run this (repo root). It prints per-batch row counts, shows which batch each missing fixture belongs to, and lists batches that are present vs missing.

uv run python3 - <<'PY'
import pandas as pd
from pathlib import Path
import math, json

SEASON = 2025
BASE = Path(f"data/seasons/{SEASON}")
BATCH_SIZE = 20

# load fixture list and existing merged/norm lists
fl = pd.read_parquet(BASE / f"fixtures_list_{SEASON}.parquet")
fixture_ids = list(fl["fixture.id"].astype(int))
# map fixture id -> position
pos_map = {fid:i for i,fid in enumerate(fixture_ids)}

# batches present (files)
batch_files = sorted(BASE.glob("fixtures_detailed_batch_*.parquet"))
present_batch_idxs = sorted([int(p.stem.split('_')[-1]) for p in batch_files]) if batch_files else []

print("Found batch files:", len(batch_files))
total_rows = 0
for f in batch_files:
    try:
        n = len(pd.read_parquet(f))
    except Exception as e:
        n = f"ERROR: {e}"
    print(f.name, "-", n)
    if isinstance(n,int): total_rows += n
print("Sum rows in batch files:", total_rows)
print()

# which fixture ids are missing from merged/normalized matches?
matches = pd.read_parquet(BASE / "matches.parquet")
m_ids = set(matches["fixture_id"].dropna().astype(int).tolist())
missing = [fid for fid in fixture_ids if fid not in m_ids]
print("Missing fixtures count:", len(missing))

# map missing fixtures -> batch index
batch_map = {}
for fid in missing:
    pos = pos_map[fid]
    bidx = pos // BATCH_SIZE
    batch_map.setdefault(bidx, []).append(fid)

print("Batches that should contain missing fixtures (batch_index -> count):")
for bi in sorted(batch_map):
    flag = "PRESENT" if bi in present_batch_idxs else "MISSING_FILE"
    print(f"  batch_{bi:04d} -> {len(batch_map[bi])} fixtures  [{flag}]")
# show a few batch indexes that are missing file
missing_files = [bi for bi in batch_map if bi not in present_batch_idxs]
print()
print("Missing batch files (indexes):", missing_files)
if missing_files:
    print("Sample missing fixture ids from first missing batch:", batch_map[missing_files[0]][:20])
PY
