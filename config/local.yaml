# Local development configuration
# Use for testing with smaller datasets

data:
  raw_dir: "data/01-raw"
  preprocessed_dir: "data/02-preprocessed"
  features_dir: "data/03-features"
  predictions_dir: "data/04-predictions"
  models_dir: "callibration"

league: "premier_league"
seasons: [2020, 2021, 2022, 2023, 2024, 2025]

preprocessing:
  batch_size: 100
  error_handling: "log"
  include_player_features: true
  include_events: true
  output_format: "parquet"

features:
  form_window: 3          # TeamFormFeatureEngineer: last N matches (tuned from 5)
  ema_span: 15            # EMA decay span (tuned from 10)
  include_h2h: true
  include_team_stats: true

  lineup_lookback: 5      # LineupStabilityFeatureEngineer (was 3)
  star_top_n: 5           # StarPlayerFeatureEngineer (was 3)
  star_min_matches: 5
  rating_lookback: 10     # TeamRatingFeatureEngineer (tuned from 7)
  key_player_top_n: 5     # KeyPlayerAbsenceFeatureEngineer
  discipline_lookback: 3  # DisciplineFeatureEngineer (tuned from 5)
  goal_timing_lookback: 10 # GoalTimingFeatureEngineer (tuned from 15)

model:
  type: "random_forest"
  test_size: 0.1
  random_state: 42

  params:
    random_forest:
      n_estimators: 227
      max_depth: 4
      min_samples_split: 19
      min_samples_leaf: 10
      max_features: 0.9

    xgboost:
      n_estimators: 200
      max_depth: 6
      learning_rate: 0.05
      subsample: 0.8
      colsample_bytree: 0.8
      min_child_weight: 1
      reg_alpha: 0.0
      reg_lambda: 1.0

    lightgbm:
      n_estimators: 200
      max_depth: 6
      learning_rate: 0.05
      subsample: 0.8
      colsample_bytree: 0.8
      min_child_weight: 0.001
      reg_alpha: 0.0
      reg_lambda: 0.0
      num_leaves: 31

    catboost:
      iterations: 100
      depth: 6
      learning_rate: 0.05
      subsample: 0.8
      l2_leaf_reg: 1.0

    logistic_regression:
      C: 1.0
      solver: "lbfgs"
      max_iter: 1000
      penalty: "l2"

mlflow:
  tracking_uri: "mlruns"
  experiment_name: "bettip-experiments"
  autolog: true

inference:
  batch_size: 32
  output_format: "csv"
  min_confidence: 0.6

logging:
  level: "DEBUG"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"