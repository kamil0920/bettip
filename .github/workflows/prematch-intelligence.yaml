name: Pre-Match Intelligence
# Unified workflow: combines schedule fetching, ML predictions, CLV tracking, and lineup collection

on:
  schedule:
    - cron: '0 7 * * *'     # 7 AM UTC: Morning predictions + CLV tracking
    - cron: '30 9-23 * * *' # Every hour at :30: Check for lineup window

  workflow_dispatch:
    inputs:
      leagues:
        description: 'Leagues to monitor (space-separated, or "all")'
        required: false
        default: 'all'
        type: string
      notify:
        description: 'Send Telegram notifications'
        required: false
        default: true
        type: boolean

permissions:
  contents: write

env:
  ALL_LEAGUES: "premier_league la_liga serie_a bundesliga ligue_1"
  HF_TOKEN: ${{ secrets.HF_TOKEN }}

jobs:
  # ==========================================================================
  # JOB 1: Morning predictions (7 AM UTC)
  # - Fetch schedule from API-Football
  # - Update previous results (CLV tracking)
  # - Run ML predictions
  # - Import to CLV tracker
  # - Send Telegram summary
  # ==========================================================================
  morning-predictions:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || (github.event_name == 'schedule' && github.event.schedule == '0 7 * * *')

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3

      - name: Cache UV dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            .venv
          key: ${{ runner.os }}-uv-${{ hashFiles('uv.lock') }}
          restore-keys: |
            ${{ runner.os }}-uv-

      - name: Set up Python
        run: uv python install 3.10

      - name: Install dependencies
        run: uv sync --frozen

      - name: Create .env file
        run: |
          echo "API_FOOTBALL_KEY=${{ secrets.API_FOOTBALL_KEY }}" > .env
          echo "HF_TOKEN=${{ secrets.HF_TOKEN }}" >> .env

      - name: Download data from HF Hub
        run: |
          echo "Downloading features and models..."
          uv run python entrypoints/download_data.py

      - name: Update previous results (CLV tracking)
        run: |
          echo "Updating results for previous predictions..."
          uv run python experiments/update_results.py 2>&1 || echo "Results update skipped (no previous predictions)"

      - name: Determine leagues
        id: leagues
        run: |
          LEAGUE_INPUT="${{ github.event.inputs.leagues || 'all' }}"
          if [ "$LEAGUE_INPUT" = "all" ]; then
            LEAGUES="${ALL_LEAGUES}"
          else
            LEAGUES="$LEAGUE_INPUT"
          fi
          echo "leagues=$LEAGUES" >> $GITHUB_OUTPUT

      - name: Fetch daily schedule
        run: |
          echo "Fetching today's match schedule..."
          uv run python -m src.data_collection.match_scheduler --fetch --leagues ${{ steps.leagues.outputs.leagues }}

      - name: Run ML predictions
        id: predict
        run: |
          echo "Running ML predictions..."
          uv run python -m src.data_collection.match_scheduler --predict --edge 0.05

          # Get counts
          if [ -f data/06-prematch/today_schedule.json ]; then
            TOTAL=$(uv run python -c "import json; print(json.load(open('data/06-prematch/today_schedule.json'))['total_matches'])")
            echo "total_matches=$TOTAL" >> $GITHUB_OUTPUT
          else
            echo "total_matches=0" >> $GITHUB_OUTPUT
          fi

          if [ -f data/06-prematch/interesting_matches.json ]; then
            INTERESTING=$(uv run python -c "import json; print(json.load(open('data/06-prematch/interesting_matches.json'))['interesting_count'])")
            echo "interesting_count=$INTERESTING" >> $GITHUB_OUTPUT
          else
            echo "interesting_count=0" >> $GITHUB_OUTPUT
          fi

      - name: Generate recommendations CSV
        id: recommendations
        run: |
          echo "Generating recommendations..."
          uv run python experiments/generate_daily_recommendations.py --min-edge 5 2>&1 | tee predictions_log.txt || true

          # Find generated file
          DATE=$(date +%Y%m%d)
          REC_FILE=$(ls -t data/05-recommendations/rec_${DATE}_*.csv 2>/dev/null | head -1)

          if [ -n "$REC_FILE" ]; then
            COUNT=$(wc -l < "$REC_FILE")
            echo "predictions_count=$((COUNT - 1))" >> $GITHUB_OUTPUT
            echo "predictions_file=$REC_FILE" >> $GITHUB_OUTPUT
          else
            echo "predictions_count=0" >> $GITHUB_OUTPUT
          fi

      - name: Import to CLV tracker
        if: steps.recommendations.outputs.predictions_count > 0
        run: |
          REC_FILE="${{ steps.recommendations.outputs.predictions_file }}"
          if [ -n "$REC_FILE" ] && [ -f "$REC_FILE" ]; then
            uv run python experiments/clv_workflow.py import --file "$REC_FILE" 2>&1 || true
          fi

      - name: Upload prematch data to HF Hub
        run: |
          echo "Uploading prematch data to HF Hub..."
          uv run python -c "
          import os
          from huggingface_hub import HfApi
          from pathlib import Path

          api = HfApi(token=os.getenv('HF_TOKEN'))
          repo_id = 'czlowiekZplanety/bettip-data'

          for folder in ['data/05-recommendations', 'data/06-prematch']:
              if Path(folder).exists():
                  api.upload_folder(
                      folder_path=folder,
                      path_in_repo=folder,
                      repo_id=repo_id,
                      repo_type='dataset',
                      commit_message=f'Update {folder} - $(date +%Y-%m-%d)'
                  )
                  print(f'Uploaded {folder}')
          "

      - name: Send Telegram summary
        if: steps.predict.outputs.interesting_count > 0
        env:
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: |
          if [ -n "$TELEGRAM_BOT_TOKEN" ] && [ -n "$TELEGRAM_CHAT_ID" ]; then
            uv run python << 'PYEOF'
          import json
          import os
          import requests

          with open('data/06-prematch/interesting_matches.json') as f:
              data = json.load(f)

          lines = ["*DAILY PREDICTIONS*", ""]
          lines.append(f"Total matches: {data['total_matches']}")
          lines.append(f"Interesting: {data['interesting_count']}")
          lines.append("")

          for m in data['matches'][:10]:
              pred = m.get('prediction', {})
              edge = pred.get('max_edge', 0) * 100
              market = pred.get('best_market', 'N/A')
              lines.append(f"*{m['home_team']} vs {m['away_team']}*")
              lines.append(f"  {edge:.1f}% edge on {market}")
              lines.append("")

          message = "\n".join(lines)
          token = os.environ.get('TELEGRAM_BOT_TOKEN')
          chat_id = os.environ.get('TELEGRAM_CHAT_ID')

          if token and chat_id:
              requests.post(
                  f"https://api.telegram.org/bot{token}/sendMessage",
                  data={'chat_id': chat_id, 'text': message, 'parse_mode': 'Markdown'}
              )
              print("Telegram notification sent!")
          PYEOF
          fi

      - name: Create summary
        if: always()
        run: |
          TOTAL="${{ steps.predict.outputs.total_matches || '0' }}"
          INTERESTING="${{ steps.predict.outputs.interesting_count || '0' }}"
          RECS="${{ steps.recommendations.outputs.predictions_count || '0' }}"

          echo "## Daily Predictions - $(date +%Y-%m-%d)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Total matches | $TOTAL |" >> $GITHUB_STEP_SUMMARY
          echo "| Interesting (edge >= 5%) | $INTERESTING |" >> $GITHUB_STEP_SUMMARY
          echo "| Recommendations generated | $RECS |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f data/06-prematch/interesting_matches.json ]; then
            echo "### Top Predictions" >> $GITHUB_STEP_SUMMARY
            uv run python -c "
          import json
          with open('data/06-prematch/interesting_matches.json') as f:
              data = json.load(f)
          for m in data['matches'][:10]:
              pred = m.get('prediction', {})
              edge = pred.get('max_edge', 0) * 100
              market = pred.get('best_market', 'N/A')
              print(f'- **{m[\"home_team\"]} vs {m[\"away_team\"]}**: {edge:.1f}% edge on {market}')
          " >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: daily-predictions-${{ github.run_number }}
          path: |
            data/06-prematch/
            data/05-recommendations/
            predictions_log.txt
          retention-days: 30

  # ==========================================================================
  # JOB 2: Lineup collection (every hour at :30)
  # - Check local schedule for matches 40-50 mins away
  # - Collect lineups for interesting matches only
  # - Send Telegram alert
  # ==========================================================================
  collect-lineups:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' && github.event.schedule == '30 9-23 * * *'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3

      - name: Set up Python
        run: uv python install 3.10

      - name: Install dependencies
        run: uv sync --frozen

      - name: Create .env file
        run: |
          echo "API_FOOTBALL_KEY=${{ secrets.API_FOOTBALL_KEY }}" > .env
          echo "HF_TOKEN=${{ secrets.HF_TOKEN }}" >> .env

      - name: Download prematch data from HF Hub
        run: |
          echo "Downloading prematch schedule from HF Hub..."
          uv run python -c "
          import os
          from huggingface_hub import snapshot_download

          snapshot_download(
              repo_id='czlowiekZplanety/bettip-data',
              repo_type='dataset',
              local_dir='.',
              allow_patterns=['data/06-prematch/**'],
              token=os.getenv('HF_TOKEN')
          )
          print('Downloaded prematch data')
          " || echo "No prematch data in HF yet"

      - name: Check if collection needed
        id: check
        run: |
          uv run python -c "
          import json
          import sys
          from datetime import datetime, timezone, timedelta
          from pathlib import Path

          schedule_file = Path('data/06-prematch/today_schedule.json')
          interesting_file = Path('data/06-prematch/interesting_matches.json')

          if not schedule_file.exists():
              print('No schedule file - skipping')
              sys.exit(0)

          with open(schedule_file) as f:
              schedule = json.load(f)

          interesting_ids = set()
          if interesting_file.exists():
              with open(interesting_file) as f:
                  interesting = json.load(f)
              interesting_ids = {m['fixture_id'] for m in interesting.get('matches', [])}
              print(f'Loaded {len(interesting_ids)} interesting matches')

          now = datetime.now(timezone.utc)
          # Window 30-60 min catches all standard kickoff times (:00, :15, :30, :45)
          # With workflow running at :30, this catches matches at :00-:30 of next hour
          # Lineups are typically available ~60 min before kickoff
          window_start = now + timedelta(minutes=30)
          window_end = now + timedelta(minutes=60)

          matches_in_window = []
          for m in schedule.get('matches', []):
              kickoff = datetime.fromisoformat(m['kickoff'])
              if window_start <= kickoff <= window_end:
                  if not interesting_ids or m['fixture_id'] in interesting_ids:
                      mins = int((kickoff - now).total_seconds() / 60)
                      m['mins_until'] = mins
                      matches_in_window.append(m)

          if matches_in_window:
              print(f'COLLECT NOW! {len(matches_in_window)} match(es):')
              for m in matches_in_window:
                  print(f'  {m[\"home_team\"]} vs {m[\"away_team\"]} in {m[\"mins_until\"]} mins')
              with open('matches_to_collect.json', 'w') as f:
                  json.dump(matches_in_window, f)
          else:
              print('No interesting matches in lineup window')
          "

          if [ -f matches_to_collect.json ]; then
            echo "should_collect=true" >> $GITHUB_OUTPUT
          else
            echo "should_collect=false" >> $GITHUB_OUTPUT
          fi

      - name: Collect lineups
        if: steps.check.outputs.should_collect == 'true'
        id: collect
        run: |
          echo "Collecting lineup data..."
          uv run python -m src.data_collection.match_scheduler --collect

          if uv run python -c "import json; r=json.load(open('data/06-prematch/lineup_collection.json')); exit(0 if any(m['signals'] for m in r['recommendations']) else 1)"; then
            echo "has_signals=true" >> $GITHUB_OUTPUT
          else
            echo "has_signals=false" >> $GITHUB_OUTPUT
          fi

      - name: Send Telegram alert
        if: steps.check.outputs.should_collect == 'true' && steps.collect.outputs.has_signals == 'true'
        env:
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: |
          uv run python << 'PYEOF'
          import json
          import os
          import requests

          with open('data/06-prematch/lineup_collection.json') as f:
              results = json.load(f)

          lines = ["*LINEUP ALERT*", ""]

          for rec in results['recommendations']:
              if not rec.get('signals'):
                  continue

              lines.append(f"*{rec['match']}*")
              lines.append(f"Kickoff in {rec['mins_until']} mins")
              lines.append(f"{rec.get('home_formation', '?')} vs {rec.get('away_formation', '?')}")

              weather = rec.get('weather')
              if weather:
                  temp = weather.get('temperature', 0)
                  wind = weather.get('wind_speed', 0)
                  lines.append(f"{weather.get('conditions', '')}, {temp:.0f}C, {wind:.0f}km/h")

              lines.append("")
              for sig in rec['signals']:
                  lines.append(f"*{sig['market']}* ({sig['confidence']:.0%})")
                  lines.append(f"_{sig['reason']}_")
              lines.append("")

          if len(lines) > 2:
              message = "\n".join(lines)
              token = os.environ.get('TELEGRAM_BOT_TOKEN')
              chat_id = os.environ.get('TELEGRAM_CHAT_ID')

              if token and chat_id:
                  requests.post(
                      f"https://api.telegram.org/bot{token}/sendMessage",
                      data={'chat_id': chat_id, 'text': message, 'parse_mode': 'Markdown'}
                  )
                  print("Telegram notification sent!")
          PYEOF
