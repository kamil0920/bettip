name: Sniper Optimization (Parallel)

on:
  workflow_dispatch:
    inputs:
      bet_types:
        description: 'Bet types to optimize (comma-separated)'
        required: true
        default: 'home_win,away_win,btts,over25,under25,fouls,shots,corners,cards'
        type: string
      n_trials:
        description: 'Optuna trials per model'
        required: false
        default: '150'
        type: string
      optimize_features:
        description: 'Optimize feature engineering parameters first'
        required: false
        default: false
        type: boolean
      n_feature_trials:
        description: 'Optuna trials for feature param optimization'
        required: false
        default: '20'
        type: string
      n_feature_folds:
        description: 'CV folds for feature param optimization'
        required: false
        default: '3'
        type: string
      walkforward:
        description: 'Run walk-forward validation'
        required: false
        default: true
        type: boolean
      shap:
        description: 'Run SHAP feature importance analysis'
        required: false
        default: true
        type: boolean
      auto_rfe:
        description: 'Use RFECV to auto-find optimal feature count'
        required: false
        default: true
        type: boolean
      upload_results:
        description: 'Upload results to HF Hub'
        required: false
        default: true
        type: boolean
      save_models:
        description: 'Save trained models for deployment'
        required: false
        default: true
        type: boolean
      only_if_better:
        description: 'Only deploy markets that improved vs current'
        required: false
        default: true
        type: boolean
      comparison_metric:
        description: 'Metric to compare for improvement'
        required: false
        default: 'roi'
        type: choice
        options:
          - roi
          - sharpe
          - sortino
          - p_profit
      sample_weights:
        description: 'Use time-decayed sample weights (recent matches weighted higher)'
        required: false
        default: true
        type: boolean
      odds_threshold:
        description: 'Use odds-dependent betting thresholds (newsvendor-inspired)'
        required: false
        default: false
        type: boolean
      threshold_alpha:
        description: 'Odds-threshold adjustment strength (0=fixed, 1=full)'
        required: false
        default: '0.2'
        type: string

permissions:
  contents: write

env:
  PYTHONPATH: ${{ github.workspace }}
  HF_REPO_ID: ${{ vars.HF_REPO_ID }}

jobs:
  # First job: Parse bet types into matrix
  setup:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Set matrix
        id: set-matrix
        run: |
          BET_TYPES="${{ inputs.bet_types }}"
          # Convert comma-separated to JSON array
          JSON=$(echo "$BET_TYPES" | tr ',' '\n' | jq -R . | jq -s -c .)
          echo "matrix={\"bet_type\":$JSON}" >> $GITHUB_OUTPUT
          echo "Matrix: {\"bet_type\":$JSON}"

  # Job 2: Feature parameter optimization (only if enabled)
  feature_optimize:
    needs: setup
    if: inputs.optimize_features == true
    runs-on: ubuntu-latest
    timeout-minutes: 120  # 2 hours per bet type
    strategy:
      fail-fast: false
      max-parallel: 4
      matrix: ${{ fromJson(needs.setup.outputs.matrix) }}

    steps:
      - name: Setup Python environment
        uses: ./.github/actions/setup-python-uv

      - name: Download preprocessed data from HF
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "Feature optimization enabled - downloading preprocessed data for regeneration"
          uv run python entrypoints/download_features.py --include-preprocessed

      - name: Create directories
        run: |
          mkdir -p outputs/feature_params
          mkdir -p experiments/outputs/feature_param_optimization
          mkdir -p config/feature_params

      - name: Run feature parameter optimization for ${{ matrix.bet_type }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          N_FEATURE_TRIALS="${{ inputs.n_feature_trials }}"
          N_FEATURE_FOLDS="${{ inputs.n_feature_folds }}"

          echo "=============================================="
          echo "Feature Parameter Optimization: $BET_TYPE"
          echo "Trials: $N_FEATURE_TRIALS"
          echo "Folds: $N_FEATURE_FOLDS"
          echo "=============================================="

          uv run python experiments/run_feature_param_optimization.py \
            --bet-type "$BET_TYPE" \
            --n-trials "$N_FEATURE_TRIALS" \
            --n-folds "$N_FEATURE_FOLDS" \
            --save-config \
            --regenerate \
            2>&1 | tee "outputs/feature_params_${BET_TYPE}.log"

          echo ""
          echo "=== Optimized Feature Params ==="
          if [ -f "config/feature_params/${BET_TYPE}.yaml" ]; then
            cat "config/feature_params/${BET_TYPE}.yaml"
          else
            echo "Warning: Feature params file not created"
          fi

      - name: Collect feature param results
        if: always()
        run: |
          BET_TYPE="${{ matrix.bet_type }}"

          # Copy feature param optimization results
          for f in experiments/outputs/feature_param_optimization/*.json; do
            if [ -f "$f" ]; then
              cp "$f" outputs/feature_params/
              echo "Copied: $f"
            fi
          done

          # Copy optimized feature params config
          if [ -f "config/feature_params/${BET_TYPE}.yaml" ]; then
            cp "config/feature_params/${BET_TYPE}.yaml" outputs/feature_params/
            echo "Copied feature config: config/feature_params/${BET_TYPE}.yaml"
          fi

      - name: Upload feature params artifact for ${{ matrix.bet_type }}
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: feature-params-${{ matrix.bet_type }}-${{ github.run_number }}
          path: |
            outputs/feature_params/
            outputs/feature_params_*.log
            config/feature_params/${{ matrix.bet_type }}.yaml
          retention-days: 90

  # Job 3: Sniper optimization (runs after feature optimization if enabled)
  sniper_optimize:
    needs: [setup, feature_optimize]
    # Run even if feature_optimize was skipped (when optimize_features is false)
    if: always() && needs.setup.result == 'success' && (needs.feature_optimize.result == 'success' || needs.feature_optimize.result == 'skipped')
    runs-on: ubuntu-latest
    timeout-minutes: 150  # 2.5 hours per bet type
    strategy:
      fail-fast: false
      max-parallel: 4
      matrix: ${{ fromJson(needs.setup.outputs.matrix) }}

    steps:
      - name: Setup Python environment
        uses: ./.github/actions/setup-python-uv

      - name: Download data from HF
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"

          if echo "$BET_TYPE" | grep -qE "corners|shots|fouls|cards"; then
            echo "Niche market detected - downloading raw match_stats too"
            uv run python entrypoints/download_features.py --include-raw
          else
            uv run python entrypoints/download_features.py
          fi

      - name: Download feature params artifacts
        if: inputs.optimize_features == true
        uses: actions/download-artifact@v4
        with:
          name: feature-params-${{ matrix.bet_type }}-${{ github.run_number }}
          path: downloaded-feature-params
        continue-on-error: true

      - name: Setup feature params from artifacts
        if: inputs.optimize_features == true
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          mkdir -p config/feature_params

          # Copy feature params from downloaded artifacts
          if [ -f "downloaded-feature-params/feature_params/${BET_TYPE}.yaml" ]; then
            cp "downloaded-feature-params/feature_params/${BET_TYPE}.yaml" "config/feature_params/${BET_TYPE}.yaml"
            echo "Using feature params from previous job:"
            cat "config/feature_params/${BET_TYPE}.yaml"
          elif [ -f "downloaded-feature-params/${BET_TYPE}.yaml" ]; then
            cp "downloaded-feature-params/${BET_TYPE}.yaml" "config/feature_params/${BET_TYPE}.yaml"
            echo "Using feature params from previous job:"
            cat "config/feature_params/${BET_TYPE}.yaml"
          else
            echo "Warning: No feature params artifact found for $BET_TYPE"
            ls -la downloaded-feature-params/ || echo "No downloaded artifacts"
          fi

      - name: Verify features file
        run: |
          # Check which file the optimization scripts will actually use (fallback logic)
          SPORTMONKS_BACKUP="data/sportmonks_backup/features_with_sportmonks_odds_FULL.parquet"
          SPORTMONKS_STANDARD="data/03-features/features_with_sportmonks_odds.parquet"

          if [ -f "$SPORTMONKS_BACKUP" ]; then
            FEATURES_FILE="$SPORTMONKS_BACKUP"
            echo "Using SportMonks backup (preferred)"
          elif [ -f "$SPORTMONKS_STANDARD" ]; then
            FEATURES_FILE="$SPORTMONKS_STANDARD"
            echo "Using SportMonks standard (fallback)"
          else
            echo "::error::No SportMonks features file found!"
            echo "Checked: $SPORTMONKS_BACKUP"
            echo "Checked: $SPORTMONKS_STANDARD"
            exit 1
          fi

          COLS=$(head -1 "$FEATURES_FILE" | tr ',' '\n' | wc -l)
          ROWS=$(wc -l < "$FEATURES_FILE")
          echo "Features file: $FEATURES_FILE"
          echo "  Rows: $ROWS, Columns: $COLS"

          # Verify SportMonks odds columns exist
          if head -1 "$FEATURES_FILE" | grep -q "sm_corners_over_odds"; then
            echo "  âœ“ SportMonks odds columns present"
          else
            echo "::warning::SportMonks odds columns not found in features file"
          fi

      - name: Create directories
        run: |
          mkdir -p outputs/sniper_results
          mkdir -p experiments/outputs/sniper_optimization
          mkdir -p models

      - name: Run sniper optimization for ${{ matrix.bet_type }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          N_TRIALS="${{ inputs.n_trials }}"
          WALKFORWARD="${{ inputs.walkforward }}"
          SHAP="${{ inputs.shap }}"
          OPTIMIZE_FEATURES="${{ inputs.optimize_features }}"
          SAMPLE_WEIGHTS="${{ inputs.sample_weights }}"
          ODDS_THRESHOLD="${{ inputs.odds_threshold }}"
          THRESHOLD_ALPHA="${{ inputs.threshold_alpha }}"

          echo "=============================================="
          echo "Sniper Optimization: $BET_TYPE"
          echo "Trials: $N_TRIALS"
          echo "Walk-forward: $WALKFORWARD"
          echo "SHAP Analysis: $SHAP"
          echo "Feature Params: $OPTIMIZE_FEATURES"
          echo "Auto-RFE (RFECV): ${{ inputs.auto_rfe }}"
          echo "Sample Weights: $SAMPLE_WEIGHTS"
          echo "Odds Threshold: $ODDS_THRESHOLD"
          echo "Threshold Alpha: $THRESHOLD_ALPHA"
          echo "=============================================="

          FLAGS=""
          if [ "$WALKFORWARD" = "true" ]; then
            FLAGS="$FLAGS --walkforward"
          fi
          if [ "${{ inputs.auto_rfe }}" = "true" ]; then
            FLAGS="$FLAGS --auto-rfe"
          fi
          if [ "${{ inputs.save_models }}" = "true" ]; then
            FLAGS="$FLAGS --save-models"
          fi
          # Retail forecasting integration flags
          if [ "$SAMPLE_WEIGHTS" = "true" ]; then
            FLAGS="$FLAGS --sample-weights"
          fi
          if [ "$ODDS_THRESHOLD" = "true" ]; then
            FLAGS="$FLAGS --odds-threshold --threshold-alpha $THRESHOLD_ALPHA"
          fi

          # Check if feature params exist (from optimization job)
          FEATURE_PARAMS_FILE="config/feature_params/${BET_TYPE}.yaml"
          if [ "$OPTIMIZE_FEATURES" = "true" ] && [ -f "$FEATURE_PARAMS_FILE" ]; then
            echo "Using optimized feature params from: $FEATURE_PARAMS_FILE"
            # Run sniper optimization with feature params
            uv run python experiments/run_sniper_optimization.py \
              --bet-type "$BET_TYPE" \
              --n-optuna-trials "$N_TRIALS" \
              --feature-params "$FEATURE_PARAMS_FILE" \
              $FLAGS \
              --shap \
              2>&1 | tee "outputs/sniper_${BET_TYPE}.log"
          else
            # Run sniper optimization (unified pipeline)
            uv run python experiments/run_sniper_optimization.py \
              --bet-type "$BET_TYPE" \
              --n-optuna-trials "$N_TRIALS" \
              --shap \
              $FLAGS \
              2>&1 | tee "outputs/sniper_${BET_TYPE}.log"
          fi

      - name: Collect results
        if: always()
        run: |
          BET_TYPE="${{ matrix.bet_type }}"

          # Copy optimization results
          for f in experiments/outputs/*_full_optimization.json experiments/outputs/sniper_optimization/*.json; do
            if [ -f "$f" ]; then
              cp "$f" outputs/sniper_results/
              echo "Copied: $f"
            fi
          done

          # Copy trained models
          mkdir -p outputs/models
          for f in models/${BET_TYPE}_*.joblib; do
            if [ -f "$f" ]; then
              cp "$f" outputs/models/
              echo "Copied model: $f"
            fi
          done

      - name: Upload artifacts for ${{ matrix.bet_type }}
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sniper-${{ matrix.bet_type }}-${{ github.run_number }}
          path: |
            outputs/sniper_results/
            outputs/models/
            outputs/sniper_*.log
            experiments/outputs/*_full_optimization.json
            experiments/outputs/sniper_optimization/sniper_${{ matrix.bet_type }}_*.json
            models/${{ matrix.bet_type }}_*.joblib
          retention-days: 90

  # Aggregate results from all parallel jobs
  aggregate:
    needs: [setup, feature_optimize, sniper_optimize]
    runs-on: ubuntu-latest
    if: always() && needs.sniper_optimize.result != 'cancelled'

    steps:
      - name: Setup Python environment
        uses: ./.github/actions/setup-python-uv

      - name: Download all sniper artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: sniper-*
          path: all-results
          merge-multiple: true

      - name: Download all feature params artifacts
        if: inputs.optimize_features == true
        uses: actions/download-artifact@v4
        with:
          pattern: feature-params-*
          path: all-feature-params
          merge-multiple: true
        continue-on-error: true

      - name: Aggregate results
        run: |
          mkdir -p outputs/final_results
          mkdir -p outputs/final_results/feature_params
          mkdir -p outputs/final_results/models

          echo "=== Downloaded artifacts structure ==="
          find all-results -type f -name "*.json" | head -30
          find all-results -type f -name "*.joblib" | head -20
          echo ""

          # Copy all JSON results (flatten to single directory)
          find all-results -name "*.json" -exec cp {} outputs/final_results/ \;

          # Copy all trained models
          find all-results -name "*.joblib" -exec cp {} outputs/final_results/models/ \;
          echo "=== Trained models ==="
          ls -la outputs/final_results/models/ || echo "No models found"

          # Copy feature params if they exist
          if [ -d "all-feature-params" ]; then
            find all-feature-params -name "*.yaml" -exec cp {} outputs/final_results/feature_params/ \;
            find all-feature-params -name "*.json" -exec cp {} outputs/final_results/ \;
            echo "=== Feature param configs ==="
            ls -la outputs/final_results/feature_params/ || echo "No feature configs found"
          fi

          echo "=== Files in final_results ==="
          ls -la outputs/final_results/ || echo "No files found"
          echo ""

          # Create summary
          echo "## Sniper Optimization Results" > outputs/final_results/SUMMARY.md
          echo "" >> outputs/final_results/SUMMARY.md
          echo "**Date:** $(date -u '+%Y-%m-%d %H:%M UTC')" >> outputs/final_results/SUMMARY.md
          echo "**Bet Types:** ${{ inputs.bet_types }}" >> outputs/final_results/SUMMARY.md
          echo "**Model Trials:** ${{ inputs.n_trials }}" >> outputs/final_results/SUMMARY.md
          echo "**Feature Optimization:** ${{ inputs.optimize_features }}" >> outputs/final_results/SUMMARY.md
          if [ "${{ inputs.optimize_features }}" = "true" ]; then
            echo "**Feature Trials:** ${{ inputs.n_feature_trials }} (folds: ${{ inputs.n_feature_folds }})" >> outputs/final_results/SUMMARY.md
          fi
          echo "**Walk-forward:** ${{ inputs.walkforward }}" >> outputs/final_results/SUMMARY.md
          echo "**Sample Weights:** ${{ inputs.sample_weights }}" >> outputs/final_results/SUMMARY.md
          echo "**Odds Threshold:** ${{ inputs.odds_threshold }}" >> outputs/final_results/SUMMARY.md
          echo "" >> outputs/final_results/SUMMARY.md
          echo "| Bet Type | Model | Precision | ROI | Bets | Threshold |" >> outputs/final_results/SUMMARY.md
          echo "|----------|-------|-----------|-----|------|-----------|" >> outputs/final_results/SUMMARY.md

          # Use find to iterate over all json files (handle nested directories)
          FILE_COUNT=0
          for f in $(find outputs/final_results -maxdepth 1 -name "*.json" -type f 2>/dev/null); do
            echo "Processing: $f"
            FILE_COUNT=$((FILE_COUNT + 1))
            uv run python3 -c "
          import json
          import sys

          try:
              with open('$f') as fp:
                  data = json.load(fp)

              bet_type = data.get('bet_type', 'unknown')
              model = data.get('best_model', 'N/A')
              precision = data.get('precision', 0) or 0
              roi = data.get('roi', 0) or 0
              n_bets = data.get('n_bets', 0) or 0
              threshold = data.get('best_threshold', 0) or 0

              print(f'| {bet_type} | {model} | {precision:.1%} | {roi:+.1f}% | {n_bets} | {threshold:.2f} |')
          except Exception as e:
              print(f'Error parsing $f: {e}', file=sys.stderr)
          " >> outputs/final_results/SUMMARY.md
          done

          echo ""
          echo "Processed $FILE_COUNT JSON files"
          echo "" >> outputs/final_results/SUMMARY.md

          echo "=== Final Summary ==="
          cat outputs/final_results/SUMMARY.md

      - name: Upload final results
        uses: actions/upload-artifact@v4
        with:
          name: sniper-all-results-${{ github.run_number }}
          path: outputs/final_results/
          retention-days: 90

      - name: Generate deployment config
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          # Generate deployment config from optimization results
          # With --only-if-better, it downloads current config and compares
          FLAGS=""
          if [ "${{ inputs.only_if_better }}" = "true" ]; then
            FLAGS="--only-if-better --metric ${{ inputs.comparison_metric }}"
          fi

          uv run python scripts/generate_deployment_config.py \
            --source outputs/final_results \
            --output config/sniper_deployment.json \
            $FLAGS

          echo ""
          echo "=== Deployment Config ==="
          cat config/sniper_deployment.json | head -80

      - name: Upload to HF Hub
        if: inputs.upload_results == true
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          uv run python -c "
          from huggingface_hub import HfApi
          import os
          from pathlib import Path
          from datetime import datetime

          api = HfApi()
          token = os.environ.get('HF_TOKEN')

          if not token:
              print('No HF_TOKEN found, skipping upload')
              exit(0)

          results_dir = Path('outputs/final_results')
          if not results_dir.exists():
              print('No results to upload')
              exit(0)

          timestamp = datetime.now().strftime('%Y%m%d_%H%M')

          # Upload optimization results
          for f in results_dir.glob('*.json'):
              try:
                  api.upload_file(
                      path_or_fileobj=str(f),
                      path_in_repo=f'sniper_optimization/{timestamp}/{f.name}',
                      repo_id=os.getenv('HF_REPO_ID', 'czlowiekZplanety/bettip-data'),
                      repo_type='dataset',
                      token=token
                  )
                  print(f'Uploaded: {f.name}')
              except Exception as e:
                  print(f'Failed to upload {f.name}: {e}')

          # Upload feature param configs
          feature_params_dir = results_dir / 'feature_params'
          if feature_params_dir.exists():
              for f in feature_params_dir.glob('*.yaml'):
                  try:
                      api.upload_file(
                          path_or_fileobj=str(f),
                          path_in_repo=f'config/feature_params/{f.name}',
                          repo_id=os.getenv('HF_REPO_ID', 'czlowiekZplanety/bettip-data'),
                          repo_type='dataset',
                          token=token
                      )
                      print(f'Uploaded feature params: {f.name}')
                  except Exception as e:
                      print(f'Failed to upload {f.name}: {e}')

          # Upload trained models
          models_dir = results_dir / 'models'
          if models_dir.exists():
              for f in models_dir.glob('*.joblib'):
                  try:
                      api.upload_file(
                          path_or_fileobj=str(f),
                          path_in_repo=f'models/{f.name}',
                          repo_id=os.getenv('HF_REPO_ID', 'czlowiekZplanety/bettip-data'),
                          repo_type='dataset',
                          token=token
                      )
                      print(f'Uploaded model: {f.name}')
                  except Exception as e:
                      print(f'Failed to upload {f.name}: {e}')

          # Upload deployment config
          config_path = Path('config/sniper_deployment.json')
          if config_path.exists():
              try:
                  api.upload_file(
                      path_or_fileobj=str(config_path),
                      path_in_repo='config/sniper_deployment.json',
                      repo_id=os.getenv('HF_REPO_ID', 'czlowiekZplanety/bettip-data'),
                      repo_type='dataset',
                      token=token
                  )
                  print('Uploaded deployment config')
              except Exception as e:
                  print(f'Failed to upload config: {e}')
          "

      - name: Create job summary
        if: always()
        run: |
          echo "## Sniper Optimization Pipeline (Parallel)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Configuration" >> $GITHUB_STEP_SUMMARY
          echo "| Parameter | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Bet Types | \`${{ inputs.bet_types }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Model Trials | ${{ inputs.n_trials }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Feature Optimization | ${{ inputs.optimize_features }} |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ inputs.optimize_features }}" = "true" ]; then
            echo "| Feature Trials | ${{ inputs.n_feature_trials }} |" >> $GITHUB_STEP_SUMMARY
            echo "| Feature CV Folds | ${{ inputs.n_feature_folds }} |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "| Walk-Forward | ${{ inputs.walkforward }} |" >> $GITHUB_STEP_SUMMARY
          echo "| SHAP Analysis | ${{ inputs.shap }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Sample Weights | ${{ inputs.sample_weights }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Odds Threshold | ${{ inputs.odds_threshold }} |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ inputs.odds_threshold }}" = "true" ]; then
            echo "| Threshold Alpha | ${{ inputs.threshold_alpha }} |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "| Only If Better | ${{ inputs.only_if_better }} |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ inputs.only_if_better }}" = "true" ]; then
            echo "| Comparison Metric | ${{ inputs.comparison_metric }} |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f "outputs/final_results/SUMMARY.md" ]; then
            echo "### Results" >> $GITHUB_STEP_SUMMARY
            cat outputs/final_results/SUMMARY.md >> $GITHUB_STEP_SUMMARY
          fi

          # Show optimized feature params if available
          if [ -d "outputs/final_results/feature_params" ] && [ "$(ls -A outputs/final_results/feature_params 2>/dev/null)" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Optimized Feature Parameters" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            for f in outputs/final_results/feature_params/*.yaml; do
              if [ -f "$f" ]; then
                BET_TYPE=$(basename "$f" .yaml)
                echo "<details><summary>$BET_TYPE</summary>" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`yaml" >> $GITHUB_STEP_SUMMARY
                cat "$f" >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                echo "</details>" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
              fi
            done
          fi
