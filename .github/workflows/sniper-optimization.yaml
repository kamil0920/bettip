name: Sniper Optimization (Parallel)

on:
  workflow_dispatch:
    inputs:
      bet_types:
        description: 'Bet types to optimize (comma-separated)'
        required: true
        default: 'home_win,away_win,btts,over25,under25,fouls,shots,corners,cards'
        type: string
      n_trials:
        description: 'Optuna trials per model'
        required: false
        default: '150'
        type: string
      feature_params_mode:
        description: 'Feature params: none=defaults, best=use best from HF Hub, optimize=run fresh optimization'
        required: false
        default: 'none'
        type: choice
        options:
          - none
          - best
          - optimize
      feature_params_lock:
        description: 'Markets to lock to "best" mode even when global mode is "optimize" (comma-separated, e.g. btts,corners)'
        required: false
        default: ''
        type: string
      n_feature_trials:
        description: 'Optuna trials for feature param optimization'
        required: false
        default: '50'
        type: string
      n_feature_folds:
        description: 'CV folds for feature param optimization'
        required: false
        default: '3'
        type: string
      walkforward:
        description: 'Run walk-forward validation'
        required: false
        default: true
        type: boolean
      shap:
        description: 'Run SHAP feature importance analysis'
        required: false
        default: true
        type: boolean
      upload_results:
        description: 'Upload results to HF Hub'
        required: false
        default: true
        type: boolean
      save_models:
        description: 'Save trained models for deployment'
        required: false
        default: true
        type: boolean
      only_if_better:
        description: 'Only deploy markets that improved vs current'
        required: false
        default: true
        type: boolean
      comparison_metric:
        description: 'Metric to compare for improvement'
        required: false
        default: 'roi'
        type: choice
        options:
          - roi
          - sharpe
          - sortino
          - p_profit
      sample_weights:
        description: 'Use time-decayed sample weights (recent matches weighted higher)'
        required: false
        default: true
        type: boolean
      odds_threshold:
        description: 'Use odds-dependent betting thresholds (newsvendor-inspired)'
        required: false
        default: false
        type: boolean
      threshold_alpha:
        description: 'Odds-threshold adjustment strength (0=fixed, 1=full)'
        required: false
        default: '0.2'
        type: string
      data_path:
        description: 'Custom features parquet path (e.g., for Americas league group)'
        required: false
        default: ''
        type: string
      league_group:
        description: 'League group namespace (e.g., americas). Isolates feature params, models, and deployment config.'
        required: false
        default: ''
        type: string
      seed:
        description: 'Random seed for reproducibility'
        required: false
        default: '42'
        type: string
      fast_mode:
        description: 'Fast mode: LightGBM + XGBoost only, max 5 Optuna trials (for quick validation)'
        required: false
        default: false
        type: boolean
      calibration_method:
        description: 'Probability calibration method'
        required: false
        default: 'sigmoid'
        type: choice
        options:
          - sigmoid
          - isotonic
          - beta
          - temperature
          - venn_abers
      only_catboost:
        description: 'Run ONLY CatBoost models (for dedicated CatBoost optimization runs)'
        required: false
        default: false
        type: boolean
      model_flags:
        description: 'Comma-separated flags: no_fastai, force_two_stage_niche, holdout_folds=N, max_ece=N, cv_method=purged_kfold, embargo_days=N, pe_gate=N, no_aggressive_reg, mrmr=N, n_trials=N'
        required: false
        default: ''
        type: string
      catboost_merge:
        description: 'Two-phase: Phase 1 trains without CatBoost, Phase 2 merges CatBoost into stacking ensemble'
        required: false
        default: false
        type: boolean
      adversarial_filter:
        description: 'Adversarial filter: off=disabled, or max_passes,max_features,auc_threshold (default: 2,10,0.75, aggressive: 5,15,0.65)'
        required: false
        default: '2,10,0.75'
        type: string
      sample_weight_decay:
        description: 'Override sample weight decay rate (default: auto ~0.002). Try 0.005 for 4.5-month half-life.'
        required: false
        default: ''
        type: string
permissions:
  contents: write

env:
  PYTHONPATH: ${{ github.workspace }}
  HF_REPO_ID: ${{ vars.HF_REPO_ID }}

jobs:
  # First job: Parse bet types into matrix
  setup:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Set matrix
        id: set-matrix
        run: |
          BET_TYPES="${{ inputs.bet_types }}"
          # Convert comma-separated to JSON array
          JSON=$(echo "$BET_TYPES" | tr ',' '\n' | jq -R . | jq -s -c .)
          echo "matrix={\"bet_type\":$JSON}" >> $GITHUB_OUTPUT
          echo "Matrix: {\"bet_type\":$JSON}"

  # Job 1b: Data leakage validation gate
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Python environment
        uses: ./.github/actions/setup-python-uv
      - name: Run data leakage tests
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: uv run pytest tests/test_data_leakage.py -x -v

  # Job 2: Feature parameter optimization (only if mode=optimize)
  feature_optimize:
    needs: [setup, validate]
    if: inputs.feature_params_mode == 'optimize' && needs.setup.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 355  # ~6 hours (dedicated CatBoost runs need extra headroom)
    strategy:
      fail-fast: false
      max-parallel: 5
      matrix: ${{ fromJson(needs.setup.outputs.matrix) }}

    steps:
      - uses: actions/checkout@v4
      - name: Setup Python environment
        uses: ./.github/actions/setup-python-uv

      - name: Download preprocessed data from HF
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "Feature optimization enabled - downloading preprocessed data for regeneration"
          uv run python entrypoints/download_features.py --include-preprocessed

      - name: Create directories
        run: |
          mkdir -p outputs/feature_params
          mkdir -p experiments/outputs/feature_param_optimization
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            mkdir -p "config/feature_params/${LEAGUE_GROUP}"
          else
            mkdir -p config/feature_params
          fi

      - name: Run feature parameter optimization for ${{ matrix.bet_type }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          N_FEATURE_TRIALS="${{ inputs.n_feature_trials }}"
          N_FEATURE_FOLDS="${{ inputs.n_feature_folds }}"
          LOCK_LIST="${{ inputs.feature_params_lock }}"

          # Skip optimization for locked markets
          if echo ",$LOCK_LIST," | grep -qi ",$BET_TYPE,"; then
            echo "Market $BET_TYPE is locked to 'best' mode — skipping feature optimization"
            exit 0
          fi

          echo "=============================================="
          echo "Feature Parameter Optimization: $BET_TYPE"
          echo "Trials: $N_FEATURE_TRIALS"
          echo "Folds: $N_FEATURE_FOLDS"
          echo "Time Budget: 330min"
          echo "=============================================="

          LEAGUE_GROUP="${{ inputs.league_group }}"
          FEATURE_DIR_FLAG=""
          if [ -n "$LEAGUE_GROUP" ]; then
            FEATURE_DIR_FLAG="--feature-params-dir config/feature_params/${LEAGUE_GROUP}"
          fi

          uv run python experiments/run_feature_param_optimization.py \
            --bet-type "$BET_TYPE" \
            --n-trials "$N_FEATURE_TRIALS" \
            --n-folds "$N_FEATURE_FOLDS" \
            --save-config \
            --regenerate \
            --time-budget-minutes 330 \
            $FEATURE_DIR_FLAG \
            2>&1 | tee "outputs/feature_params_${BET_TYPE}.log"

          echo ""
          echo "=== Optimized Feature Params ==="
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            PARAMS_FILE="config/feature_params/${LEAGUE_GROUP}/${BET_TYPE}.yaml"
          else
            PARAMS_FILE="config/feature_params/${BET_TYPE}.yaml"
          fi
          if [ -f "$PARAMS_FILE" ]; then
            cat "$PARAMS_FILE"
          else
            echo "Warning: Feature params file not created"
          fi

      - name: Collect feature param results
        if: always()
        run: |
          BET_TYPE="${{ matrix.bet_type }}"

          # Copy feature param optimization results
          for f in experiments/outputs/feature_param_optimization/*.json; do
            if [ -f "$f" ]; then
              cp "$f" outputs/feature_params/
              echo "Copied: $f"
            fi
          done

          # Copy optimized feature params config
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            PARAMS_FILE="config/feature_params/${LEAGUE_GROUP}/${BET_TYPE}.yaml"
          else
            PARAMS_FILE="config/feature_params/${BET_TYPE}.yaml"
          fi
          if [ -f "$PARAMS_FILE" ]; then
            cp "$PARAMS_FILE" outputs/feature_params/
            echo "Copied feature config: $PARAMS_FILE"
          fi

      - name: Upload feature params artifact for ${{ matrix.bet_type }}
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: feature-params-${{ matrix.bet_type }}-${{ github.run_number }}
          path: |
            outputs/feature_params/
            outputs/feature_params_*.log
            config/feature_params/${{ inputs.league_group && format('{0}/', inputs.league_group) || '' }}${{ matrix.bet_type }}.yaml
          retention-days: 90

  # Job 3: Sniper optimization (runs after feature optimization if enabled)
  sniper_optimize:
    needs: [setup, feature_optimize, validate]
    # Run even if feature_optimize was skipped (when optimize_features is false)
    if: always() && needs.setup.result == 'success' && needs.validate.result == 'success' && (needs.feature_optimize.result == 'success' || needs.feature_optimize.result == 'skipped')
    runs-on: ubuntu-latest
    timeout-minutes: 355  # ~6 hours (dedicated CatBoost runs need extra headroom)
    strategy:
      fail-fast: false
      max-parallel: 5
      matrix: ${{ fromJson(needs.setup.outputs.matrix) }}

    steps:
      - uses: actions/checkout@v4
      - name: Setup Python environment
        uses: ./.github/actions/setup-python-uv

      - name: Download data from HF
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          FEATURE_PARAMS_MODE="${{ inputs.feature_params_mode }}"

          if [ "$FEATURE_PARAMS_MODE" != "none" ]; then
            echo "Feature params mode=$FEATURE_PARAMS_MODE - downloading preprocessed data for regeneration"
            uv run python entrypoints/download_features.py --include-preprocessed
          elif echo "$BET_TYPE" | grep -qE "^(corners|shots|fouls|cards|goals|hgoals|agoals|cornershc|cardshc|ht|home_win_h1|away_win_h1)(_(over|under)_[0-9]+)?$"; then
            echo "Niche market detected - downloading raw match_stats too"
            uv run python entrypoints/download_features.py --include-raw
          else
            echo "Downloading features and SportMonks odds"
            uv run python entrypoints/download_features.py
          fi

      - name: Download feature params from optimization job
        if: inputs.feature_params_mode == 'optimize'
        uses: actions/download-artifact@v4
        with:
          name: feature-params-${{ matrix.bet_type }}-${{ github.run_number }}
          path: downloaded-feature-params
        continue-on-error: true

      - name: Setup feature params from optimization job
        if: inputs.feature_params_mode == 'optimize'
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            PARAMS_DIR="config/feature_params/${LEAGUE_GROUP}"
          else
            PARAMS_DIR="config/feature_params"
          fi
          mkdir -p "$PARAMS_DIR"

          # Search for feature params YAML in downloaded artifact
          # The artifact preserves directory structure, so the file can be at various paths
          FOUND_PARAMS=""
          if [ -d "downloaded-feature-params" ]; then
            for candidate in \
              "downloaded-feature-params/config/feature_params/${BET_TYPE}.yaml" \
              "downloaded-feature-params/outputs/feature_params/${BET_TYPE}.yaml" \
              "downloaded-feature-params/feature_params/${BET_TYPE}.yaml" \
              "downloaded-feature-params/${BET_TYPE}.yaml"; do
              if [ -f "$candidate" ]; then
                FOUND_PARAMS="$candidate"
                break
              fi
            done
            # Fallback: search recursively for the YAML
            if [ -z "$FOUND_PARAMS" ]; then
              FOUND_PARAMS=$(find downloaded-feature-params -name "${BET_TYPE}.yaml" -type f 2>/dev/null | head -1)
            fi
          fi

          if [ -n "$FOUND_PARAMS" ]; then
            cp "$FOUND_PARAMS" "${PARAMS_DIR}/${BET_TYPE}.yaml"
            echo "Using feature params from optimization job ($FOUND_PARAMS):"
            cat "${PARAMS_DIR}/${BET_TYPE}.yaml"
          elif [ -f "${PARAMS_DIR}/${BET_TYPE}.yaml" ]; then
            echo "Using feature params from git checkout (locked market or pre-committed):"
            cat "${PARAMS_DIR}/${BET_TYPE}.yaml"
          else
            echo "No optimization artifact found for $BET_TYPE — falling back to HF Hub"
            uv run python scripts/hf_download_config.py "config/feature_params/${BET_TYPE}.yaml" 2>/dev/null || echo "HF fallback failed, using defaults"
            if [ -f "${PARAMS_DIR}/${BET_TYPE}.yaml" ]; then
              echo "Feature params from HF Hub:"
              cat "${PARAMS_DIR}/${BET_TYPE}.yaml"
            fi
          fi

      - name: Download best-precision feature params from HF Hub
        if: inputs.feature_params_mode == 'best'
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            PARAMS_DIR="config/feature_params/${LEAGUE_GROUP}"
            HF_PARAMS_DIR="config/feature_params/${LEAGUE_GROUP}"
          else
            PARAMS_DIR="config/feature_params"
            HF_PARAMS_DIR="config/feature_params"
          fi
          mkdir -p "$PARAMS_DIR"

          echo "Downloading best feature params from HF Hub for $BET_TYPE..."
          uv run python scripts/hf_download_config.py "${HF_PARAMS_DIR}/${BET_TYPE}.yaml" || echo "No feature params found on HF Hub for $BET_TYPE, will use defaults"

          if [ -f "${PARAMS_DIR}/${BET_TYPE}.yaml" ]; then
            echo "Using previous feature params from HF Hub:"
            cat "${PARAMS_DIR}/${BET_TYPE}.yaml"
          else
            echo "No previous params available, will use defaults"
          fi

      - name: Install deep learning dependencies
        if: inputs.fast_mode != 'true'
        run: |
          uv sync --frozen --extra dl
          # TabPFN needs HF auth for gated model download
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}

      - name: Verify features file
        run: |
          FEATURES_FILE="data/03-features/features_all_5leagues_with_odds.parquet"

          if [ ! -f "$FEATURES_FILE" ]; then
            echo "::error::Features file not found: $FEATURES_FILE"
            exit 1
          fi

          echo "Features file: $FEATURES_FILE"
          uv run python -c "
          import pandas as pd
          df = pd.read_parquet('$FEATURES_FILE')
          print(f'  Rows: {len(df)}, Columns: {len(df.columns)}')
          if 'avg_home_close' in df.columns:
              n = df['avg_home_close'].notna().sum()
              print(f'  ✓ Bookmaker odds: {n}/{len(df)} ({100*n/len(df):.1f}%)')
          else:
              print('::warning::Bookmaker odds columns not found in features file')
          "

      - name: Create directories
        run: |
          mkdir -p outputs/sniper_results
          mkdir -p experiments/outputs/sniper_optimization
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            mkdir -p "models/${LEAGUE_GROUP}"
          else
            mkdir -p models
          fi

      - name: Run sniper optimization for ${{ matrix.bet_type }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          N_TRIALS="${{ inputs.n_trials }}"
          WALKFORWARD="${{ inputs.walkforward }}"
          SHAP="${{ inputs.shap }}"
          SAMPLE_WEIGHTS="${{ inputs.sample_weights }}"
          ODDS_THRESHOLD="${{ inputs.odds_threshold }}"
          THRESHOLD_ALPHA="${{ inputs.threshold_alpha }}"
          FAST_MODE="${{ inputs.fast_mode }}"
          SEED="${{ inputs.seed }}"
          CALIBRATION_METHOD="${{ inputs.calibration_method }}"

          # Fast mode overrides n_trials to 5
          if [ "$FAST_MODE" = "true" ]; then
            N_TRIALS=5
          fi

          echo "=============================================="
          echo "Sniper Optimization: $BET_TYPE"
          echo "Trials: $N_TRIALS"
          echo "Walk-forward: $WALKFORWARD"
          echo "SHAP Analysis: $SHAP"
          echo "Feature Params Mode: ${{ inputs.feature_params_mode }}"
          echo "Sample Weights: $SAMPLE_WEIGHTS"
          echo "Odds Threshold: $ODDS_THRESHOLD"
          echo "Threshold Alpha: $THRESHOLD_ALPHA"
          echo "Fast Mode: $FAST_MODE"
          echo "Seed: $SEED"
          echo "Calibration: $CALIBRATION_METHOD"
          echo "=============================================="

          FLAGS=""
          if [ "$WALKFORWARD" = "true" ]; then
            FLAGS="$FLAGS --walkforward"
          fi
          if [ "${{ inputs.save_models }}" = "true" ]; then
            FLAGS="$FLAGS --save-models"
          fi
          # Retail forecasting integration flags
          if [ "$SAMPLE_WEIGHTS" = "true" ]; then
            FLAGS="$FLAGS --sample-weights"
          fi
          if [ "$ODDS_THRESHOLD" = "true" ]; then
            FLAGS="$FLAGS --odds-threshold --threshold-alpha $THRESHOLD_ALPHA"
          fi
          # Fast mode and seed flags
          if [ "$FAST_MODE" = "true" ]; then
            FLAGS="$FLAGS --fast"
          fi
          # Disable two-stage models for niche markets (saves ~60 trials) unless forced
          MODEL_FLAGS="${{ inputs.model_flags }}"
          # Auto-boost trials for niche markets (FastAI disabled = time budget available)
          NICHE_TRIALS_OVERRIDE=$(echo "$MODEL_FLAGS" | grep -oP 'n_trials=\K[0-9]+' || true)
          if [ -n "$NICHE_TRIALS_OVERRIDE" ]; then
            N_TRIALS="$NICHE_TRIALS_OVERRIDE"
            echo "model_flags override: n_trials=$NICHE_TRIALS_OVERRIDE"
          elif [ "$FAST_MODE" != "true" ]; then
            if [[ "$BET_TYPE" == *"_over_"* ]] || [[ "$BET_TYPE" == *"_under_"* ]] || \
               [[ "$BET_TYPE" == ht_* ]] || [[ "$BET_TYPE" == cardshc_* ]] || \
               [[ "$BET_TYPE" == cornershc_* ]] || [[ "$BET_TYPE" == *"_h1" ]]; then
              N_TRIALS=300
              echo "Auto-boosting trials for niche market: $BET_TYPE -> $N_TRIALS"
            fi
          fi
          if ! echo "$MODEL_FLAGS" | grep -q "force_two_stage_niche"; then
            if echo "$BET_TYPE" | grep -qE "^(fouls|shots|corners|cards|btts|goals|hgoals|agoals|cornershc|cardshc|ht|home_win_h1|away_win_h1)(_(over|under)_[0-9]+)?$"; then
              FLAGS="$FLAGS --no-two-stage"
            fi
          fi
          if [ -n "$SEED" ]; then
            FLAGS="$FLAGS --seed $SEED"
          fi
          # Calibration method
          if [ -n "$CALIBRATION_METHOD" ]; then
            FLAGS="$FLAGS --calibration-method $CALIBRATION_METHOD"
          fi
          # Dedicated CatBoost-only mode
          if [ "${{ inputs.only_catboost }}" = "true" ]; then
            FLAGS="$FLAGS --only-catboost"
          fi
          # Model flags: no_fastai, force_two_stage_niche
          if echo "$MODEL_FLAGS" | grep -q "no_fastai"; then
            FLAGS="$FLAGS --no-fastai"
          fi
          # Auto --no-fastai for niche line variants (saves ~90 min of wasted FastAI trials)
          if ! echo "$FLAGS" | grep -q "\-\-no-fastai"; then
            if [[ "$BET_TYPE" == *"_over_"* ]] || [[ "$BET_TYPE" == *"_under_"* ]] || \
               [[ "$BET_TYPE" == ht_* ]] || [[ "$BET_TYPE" == cardshc_* ]] || \
               [[ "$BET_TYPE" == cornershc_* ]] || [[ "$BET_TYPE" == *"_h1" ]]; then
              echo "Auto-adding --no-fastai for niche market: $BET_TYPE"
              FLAGS="$FLAGS --no-fastai"
            fi
          fi
          # Two-phase merge: Phase 1 excludes CatBoost
          if [ "${{ inputs.catboost_merge }}" = "true" ]; then
            FLAGS="$FLAGS --no-catboost"
          fi
          # Adversarial feature filtering (remove temporally leaky features)
          ADV_FILTER="${{ inputs.adversarial_filter }}"
          if [ "$ADV_FILTER" != "off" ] && [ "$ADV_FILTER" != "false" ] && [ -n "$ADV_FILTER" ]; then
            FLAGS="$FLAGS --adversarial-filter"
            ADV_PASSES=$(echo "$ADV_FILTER" | cut -d',' -f1)
            ADV_FEATURES=$(echo "$ADV_FILTER" | cut -d',' -f2)
            ADV_AUC=$(echo "$ADV_FILTER" | cut -d',' -f3)
            FLAGS="$FLAGS --adversarial-max-passes ${ADV_PASSES:-2}"
            FLAGS="$FLAGS --adversarial-max-features ${ADV_FEATURES:-10}"
            FLAGS="$FLAGS --adversarial-auc-threshold ${ADV_AUC:-0.75}"
          fi
          # Override sample weight decay rate
          DECAY_OVERRIDE="${{ inputs.sample_weight_decay }}"
          if [ -n "$DECAY_OVERRIDE" ]; then
            FLAGS="$FLAGS --decay-rate $DECAY_OVERRIDE"
          fi
          # Holdout folds and ECE threshold (parsed from model_flags: holdout_folds=N, max_ece=N)
          HOLDOUT_FOLDS=$(echo "$MODEL_FLAGS" | grep -oP 'holdout_folds=\K[0-9]+' || true)
          if [ -n "$HOLDOUT_FOLDS" ]; then
            FLAGS="$FLAGS --n-holdout-folds $HOLDOUT_FOLDS"
          fi
          MAX_ECE_VAL=$(echo "$MODEL_FLAGS" | grep -oP 'max_ece=\K[0-9.]+' || true)
          if [ -n "$MAX_ECE_VAL" ]; then
            FLAGS="$FLAGS --max-ece $MAX_ECE_VAL"
          fi
          CV_METHOD=$(echo "$MODEL_FLAGS" | grep -oP 'cv_method=\K[a-z_]+' || true)
          if [ -n "$CV_METHOD" ]; then
            FLAGS="$FLAGS --cv-method $CV_METHOD"
          fi
          EMBARGO_DAYS=$(echo "$MODEL_FLAGS" | grep -oP 'embargo_days=\K[0-9]+' || true)
          if [ -n "$EMBARGO_DAYS" ]; then
            FLAGS="$FLAGS --embargo-days $EMBARGO_DAYS"
          fi
          PE_GATE=$(echo "$MODEL_FLAGS" | grep -oP 'pe_gate=\K[0-9.]+' || true)
          if [ -n "$PE_GATE" ]; then
            FLAGS="$FLAGS --pe-gate $PE_GATE"
          fi
          # CatBoost advanced features (on by default; model_flags can disable)
          if echo "$MODEL_FLAGS" | grep -q "no_monotonic"; then
            FLAGS="$FLAGS --no-monotonic"
          fi
          if echo "$MODEL_FLAGS" | grep -q "no_transfer_learning"; then
            FLAGS="$FLAGS --no-transfer-learning"
          fi
          if echo "$MODEL_FLAGS" | grep -q "use_baseline"; then
            FLAGS="$FLAGS --use-baseline"
          fi
          if echo "$MODEL_FLAGS" | grep -q "no_aggressive_reg"; then
            FLAGS="$FLAGS --no-aggressive-reg"
          fi
          MRMR_K=$(echo "$MODEL_FLAGS" | grep -oP 'mrmr=\K[0-9]+' || true)
          if [ -n "$MRMR_K" ]; then
            FLAGS="$FLAGS --mrmr $MRMR_K"
          fi

          # Feature params: only use if mode is 'best' or 'optimize'
          # Map line variants to base market for feature params (e.g. cards_over_35 -> cards)
          BASE_BET_TYPE=$(echo "$BET_TYPE" | sed -E 's/_(over|under)_[0-9]+$//')
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            FEATURE_PARAMS_FILE="config/feature_params/${LEAGUE_GROUP}/${BASE_BET_TYPE}.yaml"
          else
            FEATURE_PARAMS_FILE="config/feature_params/${BASE_BET_TYPE}.yaml"
          fi
          FEATURE_PARAMS_MODE="${{ inputs.feature_params_mode }}"
          LOCK_LIST="${{ inputs.feature_params_lock }}"
          EXTRA_FLAGS=""

          # Override to 'best' for locked markets
          if [ "$FEATURE_PARAMS_MODE" = "optimize" ] && echo ",$LOCK_LIST," | grep -qi ",$BET_TYPE,"; then
            echo "Market $BET_TYPE is locked — overriding feature_params_mode to 'best'"
            FEATURE_PARAMS_MODE="best"
          fi

          if [ "$FEATURE_PARAMS_MODE" != "none" ] && [ -f "$FEATURE_PARAMS_FILE" ]; then
            # Verify the YAML has optimized: true (otherwise it won't regenerate features)
            if grep -q "optimized: true" "$FEATURE_PARAMS_FILE"; then
              echo "Using optimized feature params from: $FEATURE_PARAMS_FILE"
              cat "$FEATURE_PARAMS_FILE"
              EXTRA_FLAGS="--feature-params $FEATURE_PARAMS_FILE"
            else
              echo "Feature params file exists but optimized=false, skipping (would have no effect)"
            fi
          else
            if [ "$FEATURE_PARAMS_MODE" = "none" ]; then
              echo "Feature params mode: none — using default features"
            else
              echo "No feature params file found, using default features"
            fi
          fi

          # Pass custom data path if provided
          DATA_FLAG=""
          if [ -n "${{ inputs.data_path }}" ]; then
            DATA_FLAG="--data ${{ inputs.data_path }}"
          fi

          # Pass league group for namespacing
          LEAGUE_FLAG=""
          if [ -n "$LEAGUE_GROUP" ]; then
            LEAGUE_FLAG="--league-group $LEAGUE_GROUP"
          fi

          # SHAP flag (skip in fast mode for speed)
          SHAP_FLAG=""
          if [ "$SHAP" = "true" ] && [ "$FAST_MODE" != "true" ]; then
            SHAP_FLAG="--shap"
          fi

          uv run python experiments/run_sniper_optimization.py \
            --bet-type "$BET_TYPE" \
            --n-optuna-trials "$N_TRIALS" \
            $SHAP_FLAG \
            $FLAGS \
            $EXTRA_FLAGS \
            $DATA_FLAG \
            $LEAGUE_FLAG \
            2>&1 | tee "outputs/sniper_${BET_TYPE}.log"

      - name: Collect results
        if: always()
        run: |
          BET_TYPE="${{ matrix.bet_type }}"

          # Copy optimization results
          for f in experiments/outputs/*_full_optimization.json experiments/outputs/sniper_optimization/*.json; do
            if [ -f "$f" ]; then
              cp "$f" outputs/sniper_results/
              echo "Copied: $f"
            fi
          done

          # Copy trained models
          mkdir -p outputs/models
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            MODELS_GLOB="models/${LEAGUE_GROUP}/${BET_TYPE}_*.joblib"
          else
            MODELS_GLOB="models/${BET_TYPE}_*.joblib"
          fi
          for f in $MODELS_GLOB; do
            if [ -f "$f" ]; then
              cp "$f" outputs/models/
              echo "Copied model: $f"
            fi
          done

      - name: Upload artifacts for ${{ matrix.bet_type }}
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sniper-${{ matrix.bet_type }}-${{ github.run_number }}
          path: |
            outputs/sniper_results/
            outputs/models/
            outputs/sniper_*.log
            experiments/outputs/*_full_optimization.json
            experiments/outputs/sniper_optimization/sniper_${{ matrix.bet_type }}_*.json
            experiments/outputs/sniper_optimization/model_params_${{ matrix.bet_type }}.json
            experiments/outputs/sniper_optimization/holdout_preds_${{ matrix.bet_type }}.csv
            models/${{ matrix.bet_type }}_*.joblib
          retention-days: 90

  # Job 4: CatBoost merge (Phase 2 — only when catboost_merge is enabled)
  catboost_merge:
    needs: [setup, sniper_optimize]
    # always() breaks the transitive skip cascade from feature_optimize (which is often skipped)
    if: always() && needs.setup.result == 'success' && needs.sniper_optimize.result == 'success' && (inputs.catboost_merge == true || inputs.catboost_merge == 'true')
    runs-on: ubuntu-latest
    timeout-minutes: 355
    strategy:
      fail-fast: false
      max-parallel: 5
      matrix: ${{ fromJson(needs.setup.outputs.matrix) }}

    steps:
      - uses: actions/checkout@v4
      - name: Setup Python environment
        uses: ./.github/actions/setup-python-uv

      - name: Download data from HF
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          FEATURE_PARAMS_MODE="${{ inputs.feature_params_mode }}"

          if [ "$FEATURE_PARAMS_MODE" != "none" ]; then
            echo "Feature params mode=$FEATURE_PARAMS_MODE - downloading preprocessed data for regeneration"
            uv run python entrypoints/download_features.py --include-preprocessed
          elif echo "$BET_TYPE" | grep -qE "^(corners|shots|fouls|cards|goals|hgoals|agoals|cornershc|cardshc|ht|home_win_h1|away_win_h1)(_(over|under)_[0-9]+)?$"; then
            echo "Niche market detected - downloading raw match_stats too"
            uv run python entrypoints/download_features.py --include-raw
          else
            echo "Downloading features and SportMonks odds"
            uv run python entrypoints/download_features.py
          fi

      - name: Download Phase 1 artifact
        uses: actions/download-artifact@v4
        with:
          name: sniper-${{ matrix.bet_type }}-${{ github.run_number }}
          path: phase1-results

      - name: Extract Phase 1 model params
        id: phase1
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          PARAMS_FILE=$(find phase1-results -name "model_params_${BET_TYPE}.json" -type f 2>/dev/null | head -1)
          if [ -z "$PARAMS_FILE" ]; then
            echo "::error::Phase 1 model params not found for $BET_TYPE"
            echo "found=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          echo "Phase 1 params: $PARAMS_FILE"
          cat "$PARAMS_FILE" | python3 -c "
          import sys, json
          data = json.load(sys.stdin)
          if isinstance(data, list):
              d = data[0] if data else {}
          else:
              d = data
          if 'all_model_params' in d:
              print(f'Models: {list(d[\"all_model_params\"].keys())}')
          else:
              print(f'Keys: {list(d.keys())[:10]}')
          "
          echo "params_path=$PARAMS_FILE" >> $GITHUB_OUTPUT
          echo "found=true" >> $GITHUB_OUTPUT

      - name: Download best-precision feature params from HF Hub
        if: steps.phase1.outputs.found == 'true' && inputs.feature_params_mode == 'best'
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            PARAMS_DIR="config/feature_params/${LEAGUE_GROUP}"
          else
            PARAMS_DIR="config/feature_params"
          fi
          mkdir -p "$PARAMS_DIR"

          if [ -n "$LEAGUE_GROUP" ]; then
            FP_DIR="config/feature_params/${LEAGUE_GROUP}"
          else
            FP_DIR="config/feature_params"
          fi
          uv run python scripts/hf_download_config.py "${FP_DIR}/${BET_TYPE}.yaml" || echo "No feature params on HF Hub for $BET_TYPE"

      - name: Install deep learning dependencies
        if: steps.phase1.outputs.found == 'true' && inputs.fast_mode != 'true'
        run: |
          uv sync --frozen --extra dl
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}

      - name: Verify features file
        if: steps.phase1.outputs.found == 'true'
        run: |
          FEATURES_FILE="data/03-features/features_all_5leagues_with_odds.parquet"
          if [ ! -f "$FEATURES_FILE" ]; then
            echo "::error::Features file not found: $FEATURES_FILE"
            exit 1
          fi

      - name: Create directories
        if: steps.phase1.outputs.found == 'true'
        run: |
          mkdir -p outputs/sniper_results
          mkdir -p experiments/outputs/sniper_optimization
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            mkdir -p "models/${LEAGUE_GROUP}"
          else
            mkdir -p models
          fi

      - name: Run CatBoost merge (Phase 2) for ${{ matrix.bet_type }}
        if: steps.phase1.outputs.found == 'true'
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          N_TRIALS="${{ inputs.n_trials }}"
          SEED="${{ inputs.seed }}"
          CALIBRATION_METHOD="${{ inputs.calibration_method }}"
          FAST_MODE="${{ inputs.fast_mode }}"
          PARAMS_PATH="${{ steps.phase1.outputs.params_path }}"

          if [ "$FAST_MODE" = "true" ]; then
            N_TRIALS=5
          fi

          echo "=============================================="
          echo "CatBoost Merge (Phase 2): $BET_TYPE"
          echo "Phase 1 params: $PARAMS_PATH"
          echo "=============================================="

          FLAGS="--merge-catboost $PARAMS_PATH"
          if [ "${{ inputs.walkforward }}" = "true" ]; then
            FLAGS="$FLAGS --walkforward"
          fi
          if [ "${{ inputs.save_models }}" = "true" ]; then
            FLAGS="$FLAGS --save-models"
          fi
          if [ "${{ inputs.sample_weights }}" = "true" ]; then
            FLAGS="$FLAGS --sample-weights"
          fi
          if [ "${{ inputs.odds_threshold }}" = "true" ]; then
            FLAGS="$FLAGS --odds-threshold --threshold-alpha ${{ inputs.threshold_alpha }}"
          fi
          if [ "$FAST_MODE" = "true" ]; then
            FLAGS="$FLAGS --fast"
          fi
          MODEL_FLAGS="${{ inputs.model_flags }}"
          # Auto-boost trials for niche markets (FastAI disabled = time budget available)
          NICHE_TRIALS_OVERRIDE=$(echo "$MODEL_FLAGS" | grep -oP 'n_trials=\K[0-9]+' || true)
          if [ -n "$NICHE_TRIALS_OVERRIDE" ]; then
            N_TRIALS="$NICHE_TRIALS_OVERRIDE"
            echo "model_flags override: n_trials=$NICHE_TRIALS_OVERRIDE"
          elif [ "$FAST_MODE" != "true" ]; then
            if [[ "$BET_TYPE" == *"_over_"* ]] || [[ "$BET_TYPE" == *"_under_"* ]] || \
               [[ "$BET_TYPE" == ht_* ]] || [[ "$BET_TYPE" == cardshc_* ]] || \
               [[ "$BET_TYPE" == cornershc_* ]] || [[ "$BET_TYPE" == *"_h1" ]]; then
              N_TRIALS=300
              echo "Auto-boosting trials for niche market: $BET_TYPE -> $N_TRIALS"
            fi
          fi
          if ! echo "$MODEL_FLAGS" | grep -q "force_two_stage_niche"; then
            if echo "$BET_TYPE" | grep -qE "^(fouls|shots|corners|cards|btts|goals|hgoals|agoals|cornershc|cardshc|ht|home_win_h1|away_win_h1)(_(over|under)_[0-9]+)?$"; then
              FLAGS="$FLAGS --no-two-stage"
            fi
          fi
          if [ -n "$SEED" ]; then
            FLAGS="$FLAGS --seed $SEED"
          fi
          if [ -n "$CALIBRATION_METHOD" ]; then
            FLAGS="$FLAGS --calibration-method $CALIBRATION_METHOD"
          fi
          if echo "$MODEL_FLAGS" | grep -q "no_fastai"; then
            FLAGS="$FLAGS --no-fastai"
          fi
          # Auto --no-fastai for niche line variants (saves ~90 min of wasted FastAI trials)
          if ! echo "$FLAGS" | grep -q "\-\-no-fastai"; then
            if [[ "$BET_TYPE" == *"_over_"* ]] || [[ "$BET_TYPE" == *"_under_"* ]] || \
               [[ "$BET_TYPE" == ht_* ]] || [[ "$BET_TYPE" == cardshc_* ]] || \
               [[ "$BET_TYPE" == cornershc_* ]] || [[ "$BET_TYPE" == *"_h1" ]]; then
              echo "Auto-adding --no-fastai for niche market: $BET_TYPE"
              FLAGS="$FLAGS --no-fastai"
            fi
          fi
          # Adversarial feature filtering (remove temporally leaky features)
          ADV_FILTER="${{ inputs.adversarial_filter }}"
          if [ "$ADV_FILTER" != "off" ] && [ "$ADV_FILTER" != "false" ] && [ -n "$ADV_FILTER" ]; then
            FLAGS="$FLAGS --adversarial-filter"
            ADV_PASSES=$(echo "$ADV_FILTER" | cut -d',' -f1)
            ADV_FEATURES=$(echo "$ADV_FILTER" | cut -d',' -f2)
            ADV_AUC=$(echo "$ADV_FILTER" | cut -d',' -f3)
            FLAGS="$FLAGS --adversarial-max-passes ${ADV_PASSES:-2}"
            FLAGS="$FLAGS --adversarial-max-features ${ADV_FEATURES:-10}"
            FLAGS="$FLAGS --adversarial-auc-threshold ${ADV_AUC:-0.75}"
          fi
          # Override sample weight decay rate
          DECAY_OVERRIDE="${{ inputs.sample_weight_decay }}"
          if [ -n "$DECAY_OVERRIDE" ]; then
            FLAGS="$FLAGS --decay-rate $DECAY_OVERRIDE"
          fi
          # Holdout folds and ECE threshold (parsed from model_flags: holdout_folds=N, max_ece=N)
          HOLDOUT_FOLDS=$(echo "$MODEL_FLAGS" | grep -oP 'holdout_folds=\K[0-9]+' || true)
          if [ -n "$HOLDOUT_FOLDS" ]; then
            FLAGS="$FLAGS --n-holdout-folds $HOLDOUT_FOLDS"
          fi
          MAX_ECE_VAL=$(echo "$MODEL_FLAGS" | grep -oP 'max_ece=\K[0-9.]+' || true)
          if [ -n "$MAX_ECE_VAL" ]; then
            FLAGS="$FLAGS --max-ece $MAX_ECE_VAL"
          fi
          CV_METHOD=$(echo "$MODEL_FLAGS" | grep -oP 'cv_method=\K[a-z_]+' || true)
          if [ -n "$CV_METHOD" ]; then
            FLAGS="$FLAGS --cv-method $CV_METHOD"
          fi
          EMBARGO_DAYS=$(echo "$MODEL_FLAGS" | grep -oP 'embargo_days=\K[0-9]+' || true)
          if [ -n "$EMBARGO_DAYS" ]; then
            FLAGS="$FLAGS --embargo-days $EMBARGO_DAYS"
          fi
          PE_GATE=$(echo "$MODEL_FLAGS" | grep -oP 'pe_gate=\K[0-9.]+' || true)
          if [ -n "$PE_GATE" ]; then
            FLAGS="$FLAGS --pe-gate $PE_GATE"
          fi
          # CatBoost advanced features (on by default; model_flags can disable)
          if echo "$MODEL_FLAGS" | grep -q "no_monotonic"; then
            FLAGS="$FLAGS --no-monotonic"
          fi
          if echo "$MODEL_FLAGS" | grep -q "no_transfer_learning"; then
            FLAGS="$FLAGS --no-transfer-learning"
          fi
          if echo "$MODEL_FLAGS" | grep -q "use_baseline"; then
            FLAGS="$FLAGS --use-baseline"
          fi
          if echo "$MODEL_FLAGS" | grep -q "no_aggressive_reg"; then
            FLAGS="$FLAGS --no-aggressive-reg"
          fi
          MRMR_K=$(echo "$MODEL_FLAGS" | grep -oP 'mrmr=\K[0-9]+' || true)
          if [ -n "$MRMR_K" ]; then
            FLAGS="$FLAGS --mrmr $MRMR_K"
          fi

          # Feature params
          # Map line variants to base market for feature params (e.g. cards_over_35 -> cards)
          BASE_BET_TYPE=$(echo "$BET_TYPE" | sed -E 's/_(over|under)_[0-9]+$//')
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            FEATURE_PARAMS_FILE="config/feature_params/${LEAGUE_GROUP}/${BASE_BET_TYPE}.yaml"
          else
            FEATURE_PARAMS_FILE="config/feature_params/${BASE_BET_TYPE}.yaml"
          fi
          EXTRA_FLAGS=""
          FEATURE_PARAMS_MODE="${{ inputs.feature_params_mode }}"
          if [ "$FEATURE_PARAMS_MODE" != "none" ] && [ -f "$FEATURE_PARAMS_FILE" ]; then
            if grep -q "optimized: true" "$FEATURE_PARAMS_FILE"; then
              EXTRA_FLAGS="--feature-params $FEATURE_PARAMS_FILE"
            fi
          fi

          DATA_FLAG=""
          if [ -n "${{ inputs.data_path }}" ]; then
            DATA_FLAG="--data ${{ inputs.data_path }}"
          fi
          LEAGUE_FLAG=""
          if [ -n "$LEAGUE_GROUP" ]; then
            LEAGUE_FLAG="--league-group $LEAGUE_GROUP"
          fi
          SHAP_FLAG=""
          if [ "${{ inputs.shap }}" = "true" ] && [ "$FAST_MODE" != "true" ]; then
            SHAP_FLAG="--shap"
          fi

          uv run python experiments/run_sniper_optimization.py \
            --bet-type "$BET_TYPE" \
            --n-optuna-trials "$N_TRIALS" \
            $SHAP_FLAG \
            $FLAGS \
            $EXTRA_FLAGS \
            $DATA_FLAG \
            $LEAGUE_FLAG \
            2>&1 | tee "outputs/catboost_merge_${BET_TYPE}.log"

      - name: Collect results
        if: always() && steps.phase1.outputs.found == 'true'
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          for f in experiments/outputs/*_full_optimization.json experiments/outputs/sniper_optimization/*.json; do
            if [ -f "$f" ]; then
              cp "$f" outputs/sniper_results/
              echo "Copied: $f"
            fi
          done
          mkdir -p outputs/models
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            MODELS_GLOB="models/${LEAGUE_GROUP}/${BET_TYPE}_*.joblib"
          else
            MODELS_GLOB="models/${BET_TYPE}_*.joblib"
          fi
          for f in $MODELS_GLOB; do
            if [ -f "$f" ]; then
              cp "$f" outputs/models/
              echo "Copied model: $f"
            fi
          done

      - name: Upload catboost merge artifacts for ${{ matrix.bet_type }}
        if: always() && steps.phase1.outputs.found == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: catboost-merge-${{ matrix.bet_type }}-${{ github.run_number }}
          path: |
            outputs/sniper_results/
            outputs/models/
            outputs/catboost_merge_*.log
            experiments/outputs/*_full_optimization.json
            experiments/outputs/sniper_optimization/sniper_${{ matrix.bet_type }}_*.json
            experiments/outputs/sniper_optimization/holdout_preds_${{ matrix.bet_type }}.csv
            models/${{ matrix.bet_type }}_*.joblib
          retention-days: 90

  # Aggregate results from all parallel jobs
  aggregate:
    needs: [setup, validate, feature_optimize, sniper_optimize, catboost_merge]
    runs-on: ubuntu-latest
    if: always() && needs.setup.result == 'success' && needs.validate.result == 'success'

    steps:
      - uses: actions/checkout@v4
      - name: Setup Python environment
        uses: ./.github/actions/setup-python-uv

      - name: Download all sniper artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: sniper-*
          path: all-results
          merge-multiple: true

      - name: Download catboost merge artifacts (Phase 2 overwrites Phase 1)
        if: inputs.catboost_merge == true || inputs.catboost_merge == 'true'
        uses: actions/download-artifact@v4
        with:
          pattern: catboost-merge-*
          path: all-results
          merge-multiple: true
        continue-on-error: true

      - name: Download all feature params artifacts
        if: inputs.feature_params_mode == 'optimize'
        uses: actions/download-artifact@v4
        with:
          pattern: feature-params-*
          path: all-feature-params
          merge-multiple: true
        continue-on-error: true

      - name: Aggregate results
        run: |
          mkdir -p outputs/final_results
          mkdir -p outputs/final_results/feature_params
          mkdir -p outputs/final_results/models

          echo "=== Downloaded artifacts structure ==="
          find all-results -type f -name "*.json" | head -30
          find all-results -type f -name "*.joblib" | head -20
          echo ""

          # Copy all JSON results (flatten to single directory)
          find all-results -name "*.json" -exec cp {} outputs/final_results/ \;

          # Copy all trained models
          find all-results -name "*.joblib" -exec cp {} outputs/final_results/models/ \;
          echo "=== Trained models ==="
          ls -la outputs/final_results/models/ || echo "No models found"

          # Copy feature params if they exist
          if [ -d "all-feature-params" ]; then
            find all-feature-params -name "*.yaml" -exec cp {} outputs/final_results/feature_params/ \;
            find all-feature-params -name "*.json" -exec cp {} outputs/final_results/ \;
            echo "=== Feature param configs ==="
            ls -la outputs/final_results/feature_params/ || echo "No feature configs found"
          fi

          echo "=== Files in final_results ==="
          ls -la outputs/final_results/ || echo "No files found"
          echo ""

          # Create summary
          echo "## Sniper Optimization Results" > outputs/final_results/SUMMARY.md
          echo "" >> outputs/final_results/SUMMARY.md
          echo "**Date:** $(date -u '+%Y-%m-%d %H:%M UTC')" >> outputs/final_results/SUMMARY.md
          if [ -n "${{ inputs.league_group }}" ]; then
            echo "**League Group:** ${{ inputs.league_group }}" >> outputs/final_results/SUMMARY.md
          fi
          echo "**Bet Types:** ${{ inputs.bet_types }}" >> outputs/final_results/SUMMARY.md
          echo "**Model Trials:** ${{ inputs.n_trials }}" >> outputs/final_results/SUMMARY.md
          echo "**Feature Params Mode:** ${{ inputs.feature_params_mode }}" >> outputs/final_results/SUMMARY.md
          if [ "${{ inputs.feature_params_mode }}" = "optimize" ]; then
            echo "**Feature Trials:** ${{ inputs.n_feature_trials }} (folds: ${{ inputs.n_feature_folds }})" >> outputs/final_results/SUMMARY.md
          fi
          echo "**Walk-forward:** ${{ inputs.walkforward }}" >> outputs/final_results/SUMMARY.md
          if [ "${{ inputs.fast_mode }}" = "true" ]; then
            echo "**Fast Mode:** true (LGB+XGB only, 5 trials)" >> outputs/final_results/SUMMARY.md
          fi
          echo "**Seed:** ${{ inputs.seed }}" >> outputs/final_results/SUMMARY.md
          echo "**Calibration:** ${{ inputs.calibration_method }}" >> outputs/final_results/SUMMARY.md
          echo "**Sample Weights:** ${{ inputs.sample_weights }}" >> outputs/final_results/SUMMARY.md
          echo "**Odds Threshold:** ${{ inputs.odds_threshold }}" >> outputs/final_results/SUMMARY.md
          echo "" >> outputs/final_results/SUMMARY.md
          echo "| Bet Type | Model | Precision | ROI | Bets | Threshold |" >> outputs/final_results/SUMMARY.md
          echo "|----------|-------|-----------|-----|------|-----------|" >> outputs/final_results/SUMMARY.md

          # Use find to iterate over all json files (handle nested directories)
          FILE_COUNT=0
          for f in $(find outputs/final_results -maxdepth 1 -name "*.json" -type f 2>/dev/null); do
            echo "Processing: $f"
            FILE_COUNT=$((FILE_COUNT + 1))
            uv run python3 -c "
          import json
          import sys

          try:
              with open('$f') as fp:
                  data = json.load(fp)

              if isinstance(data, list):
                  entries = data
              elif isinstance(data, dict):
                  entries = [data]
              else:
                  entries = []

              for entry in entries:
                  bet_type = entry.get('bet_type', 'unknown')
                  model = entry.get('best_model', 'N/A')
                  precision = entry.get('precision', 0) or 0
                  roi = entry.get('roi', 0) or 0
                  n_bets = entry.get('n_bets', 0) or 0
                  threshold = entry.get('best_threshold', 0) or 0

                  print(f'| {bet_type} | {model} | {precision:.1%} | {roi:+.1f}% | {n_bets} | {threshold:.2f} |')
          except Exception as e:
              print(f'Error parsing $f: {e}', file=sys.stderr)
          " >> outputs/final_results/SUMMARY.md
          done

          echo ""
          echo "Processed $FILE_COUNT JSON files"
          echo "" >> outputs/final_results/SUMMARY.md

          echo "=== Final Summary ==="
          cat outputs/final_results/SUMMARY.md

      - name: Upload final results
        uses: actions/upload-artifact@v4
        with:
          name: sniper-all-results-${{ github.run_number }}
          path: outputs/final_results/
          retention-days: 90

      - name: Generate deployment config
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          # Generate deployment config from optimization results
          # Always compare against current config to protect verified markets
          FLAGS="--only-if-better --metric ${{ inputs.comparison_metric }}"

          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            DEPLOY_CONFIG="config/sniper_deployment_${LEAGUE_GROUP}.json"
          else
            DEPLOY_CONFIG="config/sniper_deployment.json"
          fi

          uv run python scripts/generate_deployment_config.py \
            --source outputs/final_results \
            --output "$DEPLOY_CONFIG" \
            $FLAGS

          echo ""
          echo "=== Deployment Config ==="
          cat "$DEPLOY_CONFIG" | head -80

      - name: Upload to HF Hub
        if: inputs.upload_results == true || inputs.upload_results == 'true'
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          LEAGUE_GROUP="${{ inputs.league_group }}"
          uv run python -c "
          from src.hf_utils import upload_file, download_file
          import os, yaml, json
          from pathlib import Path
          from datetime import datetime

          token = os.environ.get('HF_TOKEN')
          league_group = '${LEAGUE_GROUP}'

          if not token:
              print('No HF_TOKEN found, skipping upload')
              exit(0)

          results_dir = Path('outputs/final_results')
          if not results_dir.exists():
              print('No results to upload')
              exit(0)

          timestamp = datetime.now().strftime('%Y%m%d_%H%M')

          # Namespace prefix for HF Hub paths
          lg_prefix = f'{league_group}/' if league_group else ''

          # Upload optimization results
          for f in results_dir.glob('*.json'):
              try:
                  upload_file(
                      path_or_fileobj=str(f),
                      path_in_repo=f'sniper_optimization/{lg_prefix}{timestamp}/{f.name}',
                  )
                  print(f'Uploaded: {f.name}')
              except Exception as e:
                  print(f'Failed to upload {f.name}: {e}')

          # Upload feature param configs (only if precision improved)
          feature_params_dir = results_dir / 'feature_params'
          fp_repo_dir = f'config/feature_params/{league_group}' if league_group else 'config/feature_params'
          if feature_params_dir.exists():
              for f in feature_params_dir.glob('*.yaml'):
                  try:
                      with open(f) as fp:
                          new_params = yaml.safe_load(fp)
                      new_precision = new_params.get('precision') or 0

                      # Download existing best from HF Hub and compare
                      existing_precision = 0
                      try:
                          existing_path = download_file(f'{fp_repo_dir}/{f.name}')
                          with open(existing_path) as fp:
                              existing_params = yaml.safe_load(fp)
                          existing_precision = existing_params.get('precision') or 0
                      except Exception:
                          pass  # No existing file on HF Hub

                      if new_precision > existing_precision:
                          upload_file(
                              path_or_fileobj=str(f),
                              path_in_repo=f'{fp_repo_dir}/{f.name}',
                          )
                          print(f'Uploaded feature params: {f.name} (precision {existing_precision:.4f} -> {new_precision:.4f})')
                      else:
                          print(f'Skipped {f.name}: new precision {new_precision:.4f} <= existing {existing_precision:.4f}')
                  except Exception as e:
                      print(f'Failed to process {f.name}: {e}')

          # Upload trained models — only for markets that were actually updated
          # When --only-if-better is used, the deployment config contains a
          # 'comparison' block listing 'updated_markets'. We skip uploading
          # models for markets that were rejected to avoid overwriting
          # production models with untested ones.
          models_dir = results_dir / 'models'
          models_repo_dir = f'models/{league_group}' if league_group else 'models'
          if models_dir.exists():
              # Determine which markets were updated from deployment config
              updated_markets = None
              if league_group:
                  deploy_cfg_path = Path(f'config/sniper_deployment_{league_group}.json')
              else:
                  deploy_cfg_path = Path('config/sniper_deployment.json')
              if deploy_cfg_path.exists():
                  try:
                      with open(deploy_cfg_path) as fp:
                          deploy_cfg = json.load(fp)
                      comparison = deploy_cfg.get('comparison', {})
                      if 'updated_markets' in comparison:
                          updated_markets = set(comparison['updated_markets'])
                          print(f'Filtering model uploads to updated markets: {updated_markets}')
                  except Exception as e:
                      print(f'Warning: could not read deployment config for filtering: {e}')

              # Known market names sorted longest-first for greedy filename matching
              known_markets = sorted(
                  ['home_win', 'away_win', 'over25', 'under25', 'fouls', 'shots', 'corners', 'btts', 'cards',
                   'cards_over_15', 'cards_over_25', 'cards_over_35',
                   'cards_over_45', 'cards_over_55', 'cards_over_65',
                   'cards_under_15', 'cards_under_25', 'cards_under_35',
                   'cards_under_45', 'cards_under_55', 'cards_under_65',
                   'corners_over_85', 'corners_over_95', 'corners_over_105', 'corners_over_115',
                   'corners_under_85', 'corners_under_95', 'corners_under_105', 'corners_under_115',
                   'shots_over_255', 'shots_over_265', 'shots_over_275', 'shots_over_285', 'shots_over_295',
                   'shots_under_255', 'shots_under_265', 'shots_under_275', 'shots_under_285', 'shots_under_295',
                   'fouls_over_235', 'fouls_over_245', 'fouls_over_255', 'fouls_over_265',
                   'fouls_under_235', 'fouls_under_245', 'fouls_under_255', 'fouls_under_265',
                   # Goals (1.5-3.5)
                   'goals_over_15', 'goals_over_25', 'goals_over_35',
                   'goals_under_15', 'goals_under_25', 'goals_under_35',
                   # Home goals (0.5-2.5)
                   'hgoals', 'hgoals_over_05', 'hgoals_over_15', 'hgoals_over_25',
                   'hgoals_under_05', 'hgoals_under_15', 'hgoals_under_25',
                   # Away goals (0.5-2.5)
                   'agoals', 'agoals_over_05', 'agoals_over_15', 'agoals_over_25',
                   'agoals_under_05', 'agoals_under_15', 'agoals_under_25',
                   # Corners handicap (0.5-2.5)
                   'cornershc', 'cornershc_over_05', 'cornershc_over_15', 'cornershc_over_25',
                   'cornershc_under_05', 'cornershc_under_15', 'cornershc_under_25',
                   # Cards handicap (0.5)
                   'cardshc', 'cardshc_over_05', 'cardshc_under_05',
                   # Half-time markets
                   'home_win_h1', 'away_win_h1',
                   'ht_over_05', 'ht_over_15', 'ht_under_05', 'ht_under_15'],
                  key=len, reverse=True
              )

              for f in models_dir.glob('*.joblib'):
                  # Parse market name from filename (e.g. home_win_lightgbm.joblib -> home_win)
                  market = None
                  for m in known_markets:
                      if f.name.startswith(m + '_'):
                          market = m
                          break

                  # Skip upload if market was not updated (only when filtering is active)
                  if updated_markets is not None and market and market not in updated_markets:
                      print(f'Skipped model (market not updated): {f.name}')
                      continue

                  try:
                      upload_file(
                          path_or_fileobj=str(f),
                          path_in_repo=f'{models_repo_dir}/{f.name}',
                      )
                      print(f'Uploaded model: {f.name}')
                  except Exception as e:
                      print(f'Failed to upload {f.name}: {e}')

          # Upload deployment config
          if league_group:
              config_path = Path(f'config/sniper_deployment_{league_group}.json')
              config_repo_path = f'config/sniper_deployment_{league_group}.json'
          else:
              config_path = Path('config/sniper_deployment.json')
              config_repo_path = 'config/sniper_deployment.json'
          if config_path.exists():
              try:
                  upload_file(
                      path_or_fileobj=str(config_path),
                      path_in_repo=config_repo_path,
                  )
                  print(f'Uploaded deployment config: {config_repo_path}')
              except Exception as e:
                  print(f'Failed to upload config: {e}')

          # --- Orphan model cleanup ---
          # After uploading, remove sniper-pattern models no longer referenced
          # by any market's saved_models in the deployment config.
          # IMPORTANT: Only cleanup models for markets in the CURRENT run's
          # bet_types to avoid deleting models for other markets.
          import re
          from huggingface_hub import HfApi
          repo_id = os.getenv('HF_REPO_ID', 'czlowiekZplanety/bettip-data')
          api = HfApi(token=token)
          try:
              print()
              print('=== Orphan Model Cleanup ===')

              # Parse current run's markets from bet_types input
              current_run_markets = set(
                  m.strip() for m in '${{ inputs.bet_types }}'.split(',') if m.strip()
              )
              print(f'Current run markets: {sorted(current_run_markets)}')

              # Re-read the just-saved deployment config (freshest source of truth)
              deploy_cfg = None
              if config_path.exists():
                  with open(config_path) as fp:
                      deploy_cfg = json.load(fp)

              if deploy_cfg:
                  # Collect all referenced model filenames
                  referenced = set()
                  for mcfg in deploy_cfg.get('markets', {}).values():
                      for mp in mcfg.get('saved_models', []):
                          referenced.add(os.path.basename(mp))

                  # Sniper naming pattern — only these are cleanup candidates
                  known_markets_list = [
                      'home_win', 'away_win', 'over25', 'under25',
                      'fouls', 'shots', 'corners', 'btts', 'cards',
                      # Cards (1.5-6.5)
                      'cards_over_15', 'cards_over_25', 'cards_over_35',
                      'cards_over_45', 'cards_over_55', 'cards_over_65',
                      'cards_under_15', 'cards_under_25', 'cards_under_35',
                      'cards_under_45', 'cards_under_55', 'cards_under_65',
                      # Corners (8.5-11.5)
                      'corners_over_85', 'corners_over_95', 'corners_over_105', 'corners_over_115',
                      'corners_under_85', 'corners_under_95', 'corners_under_105', 'corners_under_115',
                      # Shots (25.5-29.5)
                      'shots_over_255', 'shots_over_265', 'shots_over_275', 'shots_over_285', 'shots_over_295',
                      'shots_under_255', 'shots_under_265', 'shots_under_275', 'shots_under_285', 'shots_under_295',
                      # Fouls (23.5-26.5)
                      'fouls_over_235', 'fouls_over_245', 'fouls_over_255', 'fouls_over_265',
                      'fouls_under_235', 'fouls_under_245', 'fouls_under_255', 'fouls_under_265',
                      # Goals (1.5-3.5)
                      'goals_over_15', 'goals_over_25', 'goals_over_35',
                      'goals_under_15', 'goals_under_25', 'goals_under_35',
                      # Home goals (0.5-2.5)
                      'hgoals', 'hgoals_over_05', 'hgoals_over_15', 'hgoals_over_25',
                      'hgoals_under_05', 'hgoals_under_15', 'hgoals_under_25',
                      # Away goals (0.5-2.5)
                      'agoals', 'agoals_over_05', 'agoals_over_15', 'agoals_over_25',
                      'agoals_under_05', 'agoals_under_15', 'agoals_under_25',
                      # Corners handicap (0.5-2.5)
                      'cornershc', 'cornershc_over_05', 'cornershc_over_15', 'cornershc_over_25',
                      'cornershc_under_05', 'cornershc_under_15', 'cornershc_under_25',
                      # Cards handicap (0.5)
                      'cardshc', 'cardshc_over_05', 'cardshc_under_05',
                      # Half-time markets
                      'home_win_h1', 'away_win_h1',
                      'ht_over_05', 'ht_over_15', 'ht_under_05', 'ht_under_15',
                  ]
                  # Sort longest-first for greedy prefix matching
                  known_markets_sorted = sorted(known_markets_list, key=len, reverse=True)
                  known_types = [
                      'lightgbm', 'catboost', 'xgboost', 'fastai',
                      'two_stage_lgb', 'two_stage_xgb',
                  ]
                  sniper_pat = re.compile(
                      r'^(' + '|'.join(known_markets_list) + r')_'
                      r'(' + '|'.join(known_types) + r')\.joblib$'
                  )

                  def get_model_market(filename):
                      # Extract market name from model filename using greedy match
                      for m in known_markets_sorted:
                          if filename.startswith(m + '_'):
                              return m
                      return None

                  models_prefix = f'models/{league_group}/' if league_group else 'models/'
                  all_files = api.list_repo_files(repo_id=repo_id, repo_type='dataset')
                  hub_models = [f for f in all_files if f.startswith(models_prefix) and f.endswith('.joblib')]

                  orphans = [
                      m for m in hub_models
                      if sniper_pat.match(os.path.basename(m))
                      and os.path.basename(m) not in referenced
                      and get_model_market(os.path.basename(m)) in current_run_markets
                  ]

                  if orphans:
                      print(f'Found {len(orphans)} orphan model(s) to delete (scoped to current run markets):')
                      for orphan in orphans:
                          try:
                              api.delete_file(
                                  path_in_repo=orphan,
                                  repo_id=repo_id,
                                  repo_type='dataset',
                                  token=token,
                                  commit_message=f'Cleanup orphan model: {os.path.basename(orphan)}',
                              )
                              print(f'  Deleted: {orphan}')
                          except Exception as e:
                              print(f'  Failed to delete {orphan}: {e}')
                  else:
                      print('No orphan models found for current run markets.')
              else:
                  print('No deployment config available — skipping cleanup.')
          except Exception as e:
              print(f'Orphan cleanup failed (non-fatal): {e}')
          "

      - name: Create job summary
        if: always()
        run: |
          echo "## Sniper Optimization Pipeline (Parallel)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Configuration" >> $GITHUB_STEP_SUMMARY
          echo "| Parameter | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|-------|" >> $GITHUB_STEP_SUMMARY
          if [ -n "${{ inputs.league_group }}" ]; then
            echo "| League Group | \`${{ inputs.league_group }}\` |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "| Bet Types | \`${{ inputs.bet_types }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Model Trials | ${{ inputs.n_trials }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Feature Params Mode | ${{ inputs.feature_params_mode }} |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ inputs.feature_params_mode }}" = "optimize" ]; then
            echo "| Feature Trials | ${{ inputs.n_feature_trials }} |" >> $GITHUB_STEP_SUMMARY
            echo "| Feature CV Folds | ${{ inputs.n_feature_folds }} |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "| Walk-Forward | ${{ inputs.walkforward }} |" >> $GITHUB_STEP_SUMMARY
          echo "| SHAP Analysis | ${{ inputs.shap }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Fast Mode | ${{ inputs.fast_mode }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Seed | ${{ inputs.seed }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Calibration | ${{ inputs.calibration_method }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Sample Weights | ${{ inputs.sample_weights }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Odds Threshold | ${{ inputs.odds_threshold }} |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ inputs.odds_threshold }}" = "true" ]; then
            echo "| Threshold Alpha | ${{ inputs.threshold_alpha }} |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "| Only If Better | ${{ inputs.only_if_better }} |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ inputs.only_if_better }}" = "true" ]; then
            echo "| Comparison Metric | ${{ inputs.comparison_metric }} |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f "outputs/final_results/SUMMARY.md" ]; then
            echo "### Results" >> $GITHUB_STEP_SUMMARY
            cat outputs/final_results/SUMMARY.md >> $GITHUB_STEP_SUMMARY
          fi

          # Show optimized feature params if available
          if [ -d "outputs/final_results/feature_params" ] && [ "$(ls -A outputs/final_results/feature_params 2>/dev/null)" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Optimized Feature Parameters" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            for f in outputs/final_results/feature_params/*.yaml; do
              if [ -f "$f" ]; then
                BET_TYPE=$(basename "$f" .yaml)
                echo "<details><summary>$BET_TYPE</summary>" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`yaml" >> $GITHUB_STEP_SUMMARY
                cat "$f" >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                echo "</details>" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
              fi
            done
          fi
