name: Sniper Optimization (Parallel)

on:
  workflow_dispatch:
    inputs:
      bet_types:
        description: 'Bet types to optimize (comma-separated)'
        required: true
        default: 'home_win,away_win,btts,over25,under25,fouls,shots,corners,cards'
        type: string
      n_trials:
        description: 'Optuna trials per model'
        required: false
        default: '150'
        type: string
      feature_params_mode:
        description: 'Feature params: none=defaults, best=use best from HF Hub, optimize=run fresh optimization'
        required: false
        default: 'none'
        type: choice
        options:
          - none
          - best
          - optimize
      feature_params_lock:
        description: 'Markets to lock to "best" mode even when global mode is "optimize" (comma-separated, e.g. btts,corners)'
        required: false
        default: ''
        type: string
      n_feature_trials:
        description: 'Optuna trials for feature param optimization'
        required: false
        default: '50'
        type: string
      n_feature_folds:
        description: 'CV folds for feature param optimization'
        required: false
        default: '5'
        type: string
      walkforward:
        description: 'Run walk-forward validation'
        required: false
        default: true
        type: boolean
      shap:
        description: 'Run SHAP feature importance analysis'
        required: false
        default: true
        type: boolean
      auto_rfe:
        description: 'Use RFECV to auto-find optimal feature count'
        required: false
        default: false
        type: boolean
      upload_results:
        description: 'Upload results to HF Hub'
        required: false
        default: true
        type: boolean
      save_models:
        description: 'Save trained models for deployment'
        required: false
        default: true
        type: boolean
      only_if_better:
        description: 'Only deploy markets that improved vs current'
        required: false
        default: true
        type: boolean
      comparison_metric:
        description: 'Metric to compare for improvement'
        required: false
        default: 'roi'
        type: choice
        options:
          - roi
          - sharpe
          - sortino
          - p_profit
      sample_weights:
        description: 'Use time-decayed sample weights (recent matches weighted higher)'
        required: false
        default: true
        type: boolean
      odds_threshold:
        description: 'Use odds-dependent betting thresholds (newsvendor-inspired)'
        required: false
        default: false
        type: boolean
      threshold_alpha:
        description: 'Odds-threshold adjustment strength (0=fixed, 1=full)'
        required: false
        default: '0.2'
        type: string
      data_path:
        description: 'Custom features parquet path (e.g., for Americas league group)'
        required: false
        default: ''
        type: string
      league_group:
        description: 'League group namespace (e.g., americas). Isolates feature params, models, and deployment config.'
        required: false
        default: ''
        type: string
      seed:
        description: 'Random seed for reproducibility'
        required: false
        default: '42'
        type: string
      fast_mode:
        description: 'Fast mode: LightGBM + XGBoost only, max 5 Optuna trials (for quick validation)'
        required: false
        default: false
        type: boolean
      calibration_method:
        description: 'Probability calibration method'
        required: false
        default: 'sigmoid'
        type: choice
        options:
          - sigmoid
          - isotonic
          - beta
          - temperature

permissions:
  contents: write

env:
  PYTHONPATH: ${{ github.workspace }}
  HF_REPO_ID: ${{ vars.HF_REPO_ID }}

jobs:
  # First job: Parse bet types into matrix
  setup:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Set matrix
        id: set-matrix
        run: |
          BET_TYPES="${{ inputs.bet_types }}"
          # Convert comma-separated to JSON array
          JSON=$(echo "$BET_TYPES" | tr ',' '\n' | jq -R . | jq -s -c .)
          echo "matrix={\"bet_type\":$JSON}" >> $GITHUB_OUTPUT
          echo "Matrix: {\"bet_type\":$JSON}"

  # Job 2: Feature parameter optimization (only if mode=optimize)
  feature_optimize:
    needs: setup
    if: inputs.feature_params_mode == 'optimize'
    runs-on: ubuntu-latest
    timeout-minutes: 180  # 3 hours per bet type
    strategy:
      fail-fast: false
      max-parallel: 4
      matrix: ${{ fromJson(needs.setup.outputs.matrix) }}

    steps:
      - uses: actions/checkout@v4
      - name: Setup Python environment
        uses: ./.github/actions/setup-python-uv

      - name: Download preprocessed data from HF
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "Feature optimization enabled - downloading preprocessed data for regeneration"
          uv run python entrypoints/download_features.py --include-preprocessed

      - name: Create directories
        run: |
          mkdir -p outputs/feature_params
          mkdir -p experiments/outputs/feature_param_optimization
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            mkdir -p "config/feature_params/${LEAGUE_GROUP}"
          else
            mkdir -p config/feature_params
          fi

      - name: Run feature parameter optimization for ${{ matrix.bet_type }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          N_FEATURE_TRIALS="${{ inputs.n_feature_trials }}"
          N_FEATURE_FOLDS="${{ inputs.n_feature_folds }}"
          LOCK_LIST="${{ inputs.feature_params_lock }}"

          # Skip optimization for locked markets
          if echo ",$LOCK_LIST," | grep -qi ",$BET_TYPE,"; then
            echo "Market $BET_TYPE is locked to 'best' mode — skipping feature optimization"
            exit 0
          fi

          echo "=============================================="
          echo "Feature Parameter Optimization: $BET_TYPE"
          echo "Trials: $N_FEATURE_TRIALS"
          echo "Folds: $N_FEATURE_FOLDS"
          echo "=============================================="

          LEAGUE_GROUP="${{ inputs.league_group }}"
          FEATURE_DIR_FLAG=""
          if [ -n "$LEAGUE_GROUP" ]; then
            FEATURE_DIR_FLAG="--feature-params-dir config/feature_params/${LEAGUE_GROUP}"
          fi

          uv run python experiments/run_feature_param_optimization.py \
            --bet-type "$BET_TYPE" \
            --n-trials "$N_FEATURE_TRIALS" \
            --n-folds "$N_FEATURE_FOLDS" \
            --save-config \
            --regenerate \
            $FEATURE_DIR_FLAG \
            2>&1 | tee "outputs/feature_params_${BET_TYPE}.log"

          echo ""
          echo "=== Optimized Feature Params ==="
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            PARAMS_FILE="config/feature_params/${LEAGUE_GROUP}/${BET_TYPE}.yaml"
          else
            PARAMS_FILE="config/feature_params/${BET_TYPE}.yaml"
          fi
          if [ -f "$PARAMS_FILE" ]; then
            cat "$PARAMS_FILE"
          else
            echo "Warning: Feature params file not created"
          fi

      - name: Collect feature param results
        if: always()
        run: |
          BET_TYPE="${{ matrix.bet_type }}"

          # Copy feature param optimization results
          for f in experiments/outputs/feature_param_optimization/*.json; do
            if [ -f "$f" ]; then
              cp "$f" outputs/feature_params/
              echo "Copied: $f"
            fi
          done

          # Copy optimized feature params config
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            PARAMS_FILE="config/feature_params/${LEAGUE_GROUP}/${BET_TYPE}.yaml"
          else
            PARAMS_FILE="config/feature_params/${BET_TYPE}.yaml"
          fi
          if [ -f "$PARAMS_FILE" ]; then
            cp "$PARAMS_FILE" outputs/feature_params/
            echo "Copied feature config: $PARAMS_FILE"
          fi

      - name: Upload feature params artifact for ${{ matrix.bet_type }}
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: feature-params-${{ matrix.bet_type }}-${{ github.run_number }}
          path: |
            outputs/feature_params/
            outputs/feature_params_*.log
            config/feature_params/${{ inputs.league_group && format('{0}/', inputs.league_group) || '' }}${{ matrix.bet_type }}.yaml
          retention-days: 90

  # Job 3: Sniper optimization (runs after feature optimization if enabled)
  sniper_optimize:
    needs: [setup, feature_optimize]
    # Run even if feature_optimize was skipped (when optimize_features is false)
    if: always() && needs.setup.result == 'success' && (needs.feature_optimize.result == 'success' || needs.feature_optimize.result == 'skipped')
    runs-on: ubuntu-latest
    timeout-minutes: 180  # 3 hours per bet type
    strategy:
      fail-fast: false
      max-parallel: 4
      matrix: ${{ fromJson(needs.setup.outputs.matrix) }}

    steps:
      - uses: actions/checkout@v4
      - name: Setup Python environment
        uses: ./.github/actions/setup-python-uv

      - name: Download data from HF
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          FEATURE_PARAMS_MODE="${{ inputs.feature_params_mode }}"

          if [ "$FEATURE_PARAMS_MODE" != "none" ]; then
            echo "Feature params mode=$FEATURE_PARAMS_MODE - downloading preprocessed data for regeneration"
            uv run python entrypoints/download_features.py --include-preprocessed
          elif echo "$BET_TYPE" | grep -qE "corners|shots|fouls|cards"; then
            echo "Niche market detected - downloading raw match_stats too"
            uv run python entrypoints/download_features.py --include-raw
          else
            echo "Downloading features and SportMonks odds"
            uv run python entrypoints/download_features.py
          fi

      - name: Download feature params from optimization job
        if: inputs.feature_params_mode == 'optimize'
        uses: actions/download-artifact@v4
        with:
          name: feature-params-${{ matrix.bet_type }}-${{ github.run_number }}
          path: downloaded-feature-params
        continue-on-error: true

      - name: Setup feature params from optimization job
        if: inputs.feature_params_mode == 'optimize'
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            PARAMS_DIR="config/feature_params/${LEAGUE_GROUP}"
          else
            PARAMS_DIR="config/feature_params"
          fi
          mkdir -p "$PARAMS_DIR"

          if [ -f "downloaded-feature-params/feature_params/${BET_TYPE}.yaml" ]; then
            cp "downloaded-feature-params/feature_params/${BET_TYPE}.yaml" "${PARAMS_DIR}/${BET_TYPE}.yaml"
            echo "Using feature params from optimization job:"
            cat "${PARAMS_DIR}/${BET_TYPE}.yaml"
          elif [ -f "downloaded-feature-params/${BET_TYPE}.yaml" ]; then
            cp "downloaded-feature-params/${BET_TYPE}.yaml" "${PARAMS_DIR}/${BET_TYPE}.yaml"
            echo "Using feature params from optimization job:"
            cat "${PARAMS_DIR}/${BET_TYPE}.yaml"
          else
            echo "Warning: No feature params artifact found for $BET_TYPE"
            ls -la downloaded-feature-params/ || echo "No downloaded artifacts"
          fi

      - name: Download best-precision feature params from HF Hub
        if: inputs.feature_params_mode == 'best'
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            PARAMS_DIR="config/feature_params/${LEAGUE_GROUP}"
            HF_PARAMS_DIR="config/feature_params/${LEAGUE_GROUP}"
          else
            PARAMS_DIR="config/feature_params"
            HF_PARAMS_DIR="config/feature_params"
          fi
          mkdir -p "$PARAMS_DIR"

          echo "Downloading best feature params from HF Hub for $BET_TYPE..."
          uv run python -c "
          from huggingface_hub import hf_hub_download
          import os, shutil

          token = os.environ.get('HF_TOKEN')
          repo_id = os.getenv('HF_REPO_ID', 'czlowiekZplanety/bettip-data')
          bet_type = '${BET_TYPE}'
          hf_params_dir = '${HF_PARAMS_DIR}'
          params_dir = '${PARAMS_DIR}'

          try:
              path = hf_hub_download(
                  repo_id=repo_id,
                  filename=f'{hf_params_dir}/{bet_type}.yaml',
                  repo_type='dataset',
                  token=token,
              )
              shutil.copy(path, f'{params_dir}/{bet_type}.yaml')
              print(f'Downloaded feature params for {bet_type}')
          except Exception as e:
              print(f'No feature params found on HF Hub for {bet_type}: {e}')
              print('Will use default features')
          "

          if [ -f "${PARAMS_DIR}/${BET_TYPE}.yaml" ]; then
            echo "Using previous feature params from HF Hub:"
            cat "${PARAMS_DIR}/${BET_TYPE}.yaml"
          else
            echo "No previous params available, will use defaults"
          fi

      - name: Install deep learning dependencies
        if: inputs.fast_mode != true
        run: |
          uv sync --frozen --extra dl
          # TabPFN needs HF auth for gated model download
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}

      - name: Verify features file
        run: |
          # Check which file the optimization scripts will actually use (fallback logic)
          SPORTMONKS_BACKUP="data/sportmonks_backup/features_with_sportmonks_odds_FULL.parquet"
          SPORTMONKS_STANDARD="data/03-features/features_with_sportmonks_odds.parquet"

          if [ -f "$SPORTMONKS_BACKUP" ]; then
            FEATURES_FILE="$SPORTMONKS_BACKUP"
            echo "Using SportMonks backup (preferred)"
          elif [ -f "$SPORTMONKS_STANDARD" ]; then
            FEATURES_FILE="$SPORTMONKS_STANDARD"
            echo "Using SportMonks standard (fallback)"
          else
            echo "::error::No SportMonks features file found!"
            echo "Checked: $SPORTMONKS_BACKUP"
            echo "Checked: $SPORTMONKS_STANDARD"
            exit 1
          fi

          echo "Features file: $FEATURES_FILE"
          uv run python -c "
          import pandas as pd
          df = pd.read_parquet('$FEATURES_FILE')
          print(f'  Rows: {len(df)}, Columns: {len(df.columns)}')
          if 'sm_corners_over_odds' in df.columns:
              print('  ✓ SportMonks odds columns present')
          else:
              print('::warning::SportMonks odds columns not found in features file')
          "

      - name: Create directories
        run: |
          mkdir -p outputs/sniper_results
          mkdir -p experiments/outputs/sniper_optimization
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            mkdir -p "models/${LEAGUE_GROUP}"
          else
            mkdir -p models
          fi

      - name: Run sniper optimization for ${{ matrix.bet_type }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          N_TRIALS="${{ inputs.n_trials }}"
          WALKFORWARD="${{ inputs.walkforward }}"
          SHAP="${{ inputs.shap }}"
          SAMPLE_WEIGHTS="${{ inputs.sample_weights }}"
          ODDS_THRESHOLD="${{ inputs.odds_threshold }}"
          THRESHOLD_ALPHA="${{ inputs.threshold_alpha }}"
          FAST_MODE="${{ inputs.fast_mode }}"
          SEED="${{ inputs.seed }}"
          CALIBRATION_METHOD="${{ inputs.calibration_method }}"

          # Fast mode overrides n_trials to 5
          if [ "$FAST_MODE" = "true" ]; then
            N_TRIALS=5
          fi

          echo "=============================================="
          echo "Sniper Optimization: $BET_TYPE"
          echo "Trials: $N_TRIALS"
          echo "Walk-forward: $WALKFORWARD"
          echo "SHAP Analysis: $SHAP"
          echo "Feature Params Mode: ${{ inputs.feature_params_mode }}"
          echo "Auto-RFE (RFECV): ${{ inputs.auto_rfe }}"
          echo "Sample Weights: $SAMPLE_WEIGHTS"
          echo "Odds Threshold: $ODDS_THRESHOLD"
          echo "Threshold Alpha: $THRESHOLD_ALPHA"
          echo "Fast Mode: $FAST_MODE"
          echo "Seed: $SEED"
          echo "Calibration: $CALIBRATION_METHOD"
          echo "=============================================="

          FLAGS=""
          if [ "$WALKFORWARD" = "true" ]; then
            FLAGS="$FLAGS --walkforward"
          fi
          if [ "${{ inputs.auto_rfe }}" = "true" ]; then
            FLAGS="$FLAGS --auto-rfe"
          fi
          if [ "${{ inputs.save_models }}" = "true" ]; then
            FLAGS="$FLAGS --save-models"
          fi
          # Retail forecasting integration flags
          if [ "$SAMPLE_WEIGHTS" = "true" ]; then
            FLAGS="$FLAGS --sample-weights"
          fi
          if [ "$ODDS_THRESHOLD" = "true" ]; then
            FLAGS="$FLAGS --odds-threshold --threshold-alpha $THRESHOLD_ALPHA"
          fi
          # Fast mode and seed flags
          if [ "$FAST_MODE" = "true" ]; then
            FLAGS="$FLAGS --fast"
          fi
          if [ -n "$SEED" ]; then
            FLAGS="$FLAGS --seed $SEED"
          fi
          # Calibration method
          if [ -n "$CALIBRATION_METHOD" ]; then
            FLAGS="$FLAGS --calibration-method $CALIBRATION_METHOD"
          fi

          # Feature params: only use if mode is 'best' or 'optimize'
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            FEATURE_PARAMS_FILE="config/feature_params/${LEAGUE_GROUP}/${BET_TYPE}.yaml"
          else
            FEATURE_PARAMS_FILE="config/feature_params/${BET_TYPE}.yaml"
          fi
          FEATURE_PARAMS_MODE="${{ inputs.feature_params_mode }}"
          LOCK_LIST="${{ inputs.feature_params_lock }}"
          EXTRA_FLAGS=""

          # Override to 'best' for locked markets
          if [ "$FEATURE_PARAMS_MODE" = "optimize" ] && echo ",$LOCK_LIST," | grep -qi ",$BET_TYPE,"; then
            echo "Market $BET_TYPE is locked — overriding feature_params_mode to 'best'"
            FEATURE_PARAMS_MODE="best"
          fi

          if [ "$FEATURE_PARAMS_MODE" != "none" ] && [ -f "$FEATURE_PARAMS_FILE" ]; then
            # Verify the YAML has optimized: true (otherwise it won't regenerate features)
            if grep -q "optimized: true" "$FEATURE_PARAMS_FILE"; then
              echo "Using optimized feature params from: $FEATURE_PARAMS_FILE"
              cat "$FEATURE_PARAMS_FILE"
              EXTRA_FLAGS="--feature-params $FEATURE_PARAMS_FILE"
            else
              echo "Feature params file exists but optimized=false, skipping (would have no effect)"
            fi
          else
            if [ "$FEATURE_PARAMS_MODE" = "none" ]; then
              echo "Feature params mode: none — using default features"
            else
              echo "No feature params file found, using default features"
            fi
          fi

          # Pass custom data path if provided
          DATA_FLAG=""
          if [ -n "${{ inputs.data_path }}" ]; then
            DATA_FLAG="--data ${{ inputs.data_path }}"
          fi

          # Pass league group for namespacing
          LEAGUE_FLAG=""
          if [ -n "$LEAGUE_GROUP" ]; then
            LEAGUE_FLAG="--league-group $LEAGUE_GROUP"
          fi

          # SHAP flag (skip in fast mode for speed)
          SHAP_FLAG=""
          if [ "$SHAP" = "true" ] && [ "$FAST_MODE" != "true" ]; then
            SHAP_FLAG="--shap"
          fi

          uv run python experiments/run_sniper_optimization.py \
            --bet-type "$BET_TYPE" \
            --n-optuna-trials "$N_TRIALS" \
            $SHAP_FLAG \
            $FLAGS \
            $EXTRA_FLAGS \
            $DATA_FLAG \
            $LEAGUE_FLAG \
            2>&1 | tee "outputs/sniper_${BET_TYPE}.log"

      - name: Collect results
        if: always()
        run: |
          BET_TYPE="${{ matrix.bet_type }}"

          # Copy optimization results
          for f in experiments/outputs/*_full_optimization.json experiments/outputs/sniper_optimization/*.json; do
            if [ -f "$f" ]; then
              cp "$f" outputs/sniper_results/
              echo "Copied: $f"
            fi
          done

          # Copy trained models
          mkdir -p outputs/models
          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            MODELS_GLOB="models/${LEAGUE_GROUP}/${BET_TYPE}_*.joblib"
          else
            MODELS_GLOB="models/${BET_TYPE}_*.joblib"
          fi
          for f in $MODELS_GLOB; do
            if [ -f "$f" ]; then
              cp "$f" outputs/models/
              echo "Copied model: $f"
            fi
          done

      - name: Upload artifacts for ${{ matrix.bet_type }}
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sniper-${{ matrix.bet_type }}-${{ github.run_number }}
          path: |
            outputs/sniper_results/
            outputs/models/
            outputs/sniper_*.log
            experiments/outputs/*_full_optimization.json
            experiments/outputs/sniper_optimization/sniper_${{ matrix.bet_type }}_*.json
            models/${{ matrix.bet_type }}_*.joblib
          retention-days: 90

  # Aggregate results from all parallel jobs
  aggregate:
    needs: [setup, feature_optimize, sniper_optimize]
    runs-on: ubuntu-latest
    if: always() && needs.sniper_optimize.result != 'cancelled'

    steps:
      - uses: actions/checkout@v4
      - name: Setup Python environment
        uses: ./.github/actions/setup-python-uv

      - name: Download all sniper artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: sniper-*
          path: all-results
          merge-multiple: true

      - name: Download all feature params artifacts
        if: inputs.feature_params_mode == 'optimize'
        uses: actions/download-artifact@v4
        with:
          pattern: feature-params-*
          path: all-feature-params
          merge-multiple: true
        continue-on-error: true

      - name: Aggregate results
        run: |
          mkdir -p outputs/final_results
          mkdir -p outputs/final_results/feature_params
          mkdir -p outputs/final_results/models

          echo "=== Downloaded artifacts structure ==="
          find all-results -type f -name "*.json" | head -30
          find all-results -type f -name "*.joblib" | head -20
          echo ""

          # Copy all JSON results (flatten to single directory)
          find all-results -name "*.json" -exec cp {} outputs/final_results/ \;

          # Copy all trained models
          find all-results -name "*.joblib" -exec cp {} outputs/final_results/models/ \;
          echo "=== Trained models ==="
          ls -la outputs/final_results/models/ || echo "No models found"

          # Copy feature params if they exist
          if [ -d "all-feature-params" ]; then
            find all-feature-params -name "*.yaml" -exec cp {} outputs/final_results/feature_params/ \;
            find all-feature-params -name "*.json" -exec cp {} outputs/final_results/ \;
            echo "=== Feature param configs ==="
            ls -la outputs/final_results/feature_params/ || echo "No feature configs found"
          fi

          echo "=== Files in final_results ==="
          ls -la outputs/final_results/ || echo "No files found"
          echo ""

          # Create summary
          echo "## Sniper Optimization Results" > outputs/final_results/SUMMARY.md
          echo "" >> outputs/final_results/SUMMARY.md
          echo "**Date:** $(date -u '+%Y-%m-%d %H:%M UTC')" >> outputs/final_results/SUMMARY.md
          if [ -n "${{ inputs.league_group }}" ]; then
            echo "**League Group:** ${{ inputs.league_group }}" >> outputs/final_results/SUMMARY.md
          fi
          echo "**Bet Types:** ${{ inputs.bet_types }}" >> outputs/final_results/SUMMARY.md
          echo "**Model Trials:** ${{ inputs.n_trials }}" >> outputs/final_results/SUMMARY.md
          echo "**Feature Params Mode:** ${{ inputs.feature_params_mode }}" >> outputs/final_results/SUMMARY.md
          if [ "${{ inputs.feature_params_mode }}" = "optimize" ]; then
            echo "**Feature Trials:** ${{ inputs.n_feature_trials }} (folds: ${{ inputs.n_feature_folds }})" >> outputs/final_results/SUMMARY.md
          fi
          echo "**Walk-forward:** ${{ inputs.walkforward }}" >> outputs/final_results/SUMMARY.md
          if [ "${{ inputs.fast_mode }}" = "true" ]; then
            echo "**Fast Mode:** true (LGB+XGB only, 5 trials)" >> outputs/final_results/SUMMARY.md
          fi
          echo "**Seed:** ${{ inputs.seed }}" >> outputs/final_results/SUMMARY.md
          echo "**Calibration:** ${{ inputs.calibration_method }}" >> outputs/final_results/SUMMARY.md
          echo "**Sample Weights:** ${{ inputs.sample_weights }}" >> outputs/final_results/SUMMARY.md
          echo "**Odds Threshold:** ${{ inputs.odds_threshold }}" >> outputs/final_results/SUMMARY.md
          echo "" >> outputs/final_results/SUMMARY.md
          echo "| Bet Type | Model | Precision | ROI | Bets | Threshold |" >> outputs/final_results/SUMMARY.md
          echo "|----------|-------|-----------|-----|------|-----------|" >> outputs/final_results/SUMMARY.md

          # Use find to iterate over all json files (handle nested directories)
          FILE_COUNT=0
          for f in $(find outputs/final_results -maxdepth 1 -name "*.json" -type f 2>/dev/null); do
            echo "Processing: $f"
            FILE_COUNT=$((FILE_COUNT + 1))
            uv run python3 -c "
          import json
          import sys

          try:
              with open('$f') as fp:
                  data = json.load(fp)

              bet_type = data.get('bet_type', 'unknown')
              model = data.get('best_model', 'N/A')
              precision = data.get('precision', 0) or 0
              roi = data.get('roi', 0) or 0
              n_bets = data.get('n_bets', 0) or 0
              threshold = data.get('best_threshold', 0) or 0

              print(f'| {bet_type} | {model} | {precision:.1%} | {roi:+.1f}% | {n_bets} | {threshold:.2f} |')
          except Exception as e:
              print(f'Error parsing $f: {e}', file=sys.stderr)
          " >> outputs/final_results/SUMMARY.md
          done

          echo ""
          echo "Processed $FILE_COUNT JSON files"
          echo "" >> outputs/final_results/SUMMARY.md

          echo "=== Final Summary ==="
          cat outputs/final_results/SUMMARY.md

      - name: Upload final results
        uses: actions/upload-artifact@v4
        with:
          name: sniper-all-results-${{ github.run_number }}
          path: outputs/final_results/
          retention-days: 90

      - name: Generate deployment config
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          # Generate deployment config from optimization results
          # With --only-if-better, it downloads current config and compares
          FLAGS=""
          if [ "${{ inputs.only_if_better }}" = "true" ]; then
            FLAGS="--only-if-better --metric ${{ inputs.comparison_metric }}"
          fi

          LEAGUE_GROUP="${{ inputs.league_group }}"
          if [ -n "$LEAGUE_GROUP" ]; then
            DEPLOY_CONFIG="config/sniper_deployment_${LEAGUE_GROUP}.json"
          else
            DEPLOY_CONFIG="config/sniper_deployment.json"
          fi

          uv run python scripts/generate_deployment_config.py \
            --source outputs/final_results \
            --output "$DEPLOY_CONFIG" \
            $FLAGS

          echo ""
          echo "=== Deployment Config ==="
          cat "$DEPLOY_CONFIG" | head -80

      - name: Upload to HF Hub
        if: inputs.upload_results == true
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          LEAGUE_GROUP="${{ inputs.league_group }}"
          uv run python -c "
          from huggingface_hub import HfApi, hf_hub_download
          import os, yaml
          from pathlib import Path
          from datetime import datetime

          api = HfApi()
          token = os.environ.get('HF_TOKEN')
          league_group = '${LEAGUE_GROUP}'

          if not token:
              print('No HF_TOKEN found, skipping upload')
              exit(0)

          results_dir = Path('outputs/final_results')
          if not results_dir.exists():
              print('No results to upload')
              exit(0)

          timestamp = datetime.now().strftime('%Y%m%d_%H%M')
          repo_id = os.getenv('HF_REPO_ID', 'czlowiekZplanety/bettip-data')

          # Namespace prefix for HF Hub paths
          lg_prefix = f'{league_group}/' if league_group else ''

          # Upload optimization results
          for f in results_dir.glob('*.json'):
              try:
                  api.upload_file(
                      path_or_fileobj=str(f),
                      path_in_repo=f'sniper_optimization/{lg_prefix}{timestamp}/{f.name}',
                      repo_id=repo_id,
                      repo_type='dataset',
                      token=token
                  )
                  print(f'Uploaded: {f.name}')
              except Exception as e:
                  print(f'Failed to upload {f.name}: {e}')

          # Upload feature param configs (only if precision improved)
          feature_params_dir = results_dir / 'feature_params'
          fp_repo_dir = f'config/feature_params/{league_group}' if league_group else 'config/feature_params'
          if feature_params_dir.exists():
              for f in feature_params_dir.glob('*.yaml'):
                  try:
                      with open(f) as fp:
                          new_params = yaml.safe_load(fp)
                      new_precision = new_params.get('precision') or 0

                      # Download existing best from HF Hub and compare
                      existing_precision = 0
                      try:
                          existing_path = hf_hub_download(
                              repo_id=repo_id,
                              filename=f'{fp_repo_dir}/{f.name}',
                              repo_type='dataset',
                              token=token,
                          )
                          with open(existing_path) as fp:
                              existing_params = yaml.safe_load(fp)
                          existing_precision = existing_params.get('precision') or 0
                      except Exception:
                          pass  # No existing file on HF Hub

                      if new_precision > existing_precision:
                          api.upload_file(
                              path_or_fileobj=str(f),
                              path_in_repo=f'{fp_repo_dir}/{f.name}',
                              repo_id=repo_id,
                              repo_type='dataset',
                              token=token,
                          )
                          print(f'Uploaded feature params: {f.name} (precision {existing_precision:.4f} -> {new_precision:.4f})')
                      else:
                          print(f'Skipped {f.name}: new precision {new_precision:.4f} <= existing {existing_precision:.4f}')
                  except Exception as e:
                      print(f'Failed to process {f.name}: {e}')

          # Upload trained models
          models_dir = results_dir / 'models'
          models_repo_dir = f'models/{league_group}' if league_group else 'models'
          if models_dir.exists():
              for f in models_dir.glob('*.joblib'):
                  try:
                      api.upload_file(
                          path_or_fileobj=str(f),
                          path_in_repo=f'{models_repo_dir}/{f.name}',
                          repo_id=repo_id,
                          repo_type='dataset',
                          token=token
                      )
                      print(f'Uploaded model: {f.name}')
                  except Exception as e:
                      print(f'Failed to upload {f.name}: {e}')

          # Upload deployment config
          if league_group:
              config_path = Path(f'config/sniper_deployment_{league_group}.json')
              config_repo_path = f'config/sniper_deployment_{league_group}.json'
          else:
              config_path = Path('config/sniper_deployment.json')
              config_repo_path = 'config/sniper_deployment.json'
          if config_path.exists():
              try:
                  api.upload_file(
                      path_or_fileobj=str(config_path),
                      path_in_repo=config_repo_path,
                      repo_id=repo_id,
                      repo_type='dataset',
                      token=token
                  )
                  print(f'Uploaded deployment config: {config_repo_path}')
              except Exception as e:
                  print(f'Failed to upload config: {e}')
          "

      - name: Create job summary
        if: always()
        run: |
          echo "## Sniper Optimization Pipeline (Parallel)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Configuration" >> $GITHUB_STEP_SUMMARY
          echo "| Parameter | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|-------|" >> $GITHUB_STEP_SUMMARY
          if [ -n "${{ inputs.league_group }}" ]; then
            echo "| League Group | \`${{ inputs.league_group }}\` |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "| Bet Types | \`${{ inputs.bet_types }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Model Trials | ${{ inputs.n_trials }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Feature Params Mode | ${{ inputs.feature_params_mode }} |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ inputs.feature_params_mode }}" = "optimize" ]; then
            echo "| Feature Trials | ${{ inputs.n_feature_trials }} |" >> $GITHUB_STEP_SUMMARY
            echo "| Feature CV Folds | ${{ inputs.n_feature_folds }} |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "| Walk-Forward | ${{ inputs.walkforward }} |" >> $GITHUB_STEP_SUMMARY
          echo "| SHAP Analysis | ${{ inputs.shap }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Fast Mode | ${{ inputs.fast_mode }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Seed | ${{ inputs.seed }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Calibration | ${{ inputs.calibration_method }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Sample Weights | ${{ inputs.sample_weights }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Odds Threshold | ${{ inputs.odds_threshold }} |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ inputs.odds_threshold }}" = "true" ]; then
            echo "| Threshold Alpha | ${{ inputs.threshold_alpha }} |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "| Only If Better | ${{ inputs.only_if_better }} |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ inputs.only_if_better }}" = "true" ]; then
            echo "| Comparison Metric | ${{ inputs.comparison_metric }} |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f "outputs/final_results/SUMMARY.md" ]; then
            echo "### Results" >> $GITHUB_STEP_SUMMARY
            cat outputs/final_results/SUMMARY.md >> $GITHUB_STEP_SUMMARY
          fi

          # Show optimized feature params if available
          if [ -d "outputs/final_results/feature_params" ] && [ "$(ls -A outputs/final_results/feature_params 2>/dev/null)" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Optimized Feature Parameters" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            for f in outputs/final_results/feature_params/*.yaml; do
              if [ -f "$f" ]; then
                BET_TYPE=$(basename "$f" .yaml)
                echo "<details><summary>$BET_TYPE</summary>" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`yaml" >> $GITHUB_STEP_SUMMARY
                cat "$f" >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                echo "</details>" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
              fi
            done
          fi
