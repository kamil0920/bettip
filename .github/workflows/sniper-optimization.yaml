name: Sniper Optimization (Parallel)

on:
  workflow_dispatch:
    inputs:
      bet_types:
        description: 'Bet types to optimize (comma-separated)'
        required: true
        default: 'home_win,away_win,btts,over25,under25,fouls,shots,corners,cards'
        type: string
      n_trials:
        description: 'Optuna trials per model'
        required: false
        default: '150'
        type: string
      optimize_features:
        description: 'Optimize feature engineering parameters first'
        required: false
        default: false
        type: boolean
      n_feature_trials:
        description: 'Optuna trials for feature param optimization'
        required: false
        default: '30'
        type: string
      walkforward:
        description: 'Run walk-forward validation'
        required: false
        default: true
        type: boolean
      shap:
        description: 'Run SHAP feature importance analysis'
        required: false
        default: true
        type: boolean
      auto_rfe:
        description: 'Use RFECV to auto-find optimal feature count'
        required: false
        default: true
        type: boolean
      upload_results:
        description: 'Upload results to HF Hub'
        required: false
        default: true
        type: boolean
      save_models:
        description: 'Save trained models for deployment'
        required: false
        default: true
        type: boolean
      only_if_better:
        description: 'Only deploy markets that improved vs current'
        required: false
        default: true
        type: boolean
      comparison_metric:
        description: 'Metric to compare for improvement'
        required: false
        default: 'roi'
        type: choice
        options:
          - roi
          - sharpe
          - sortino
          - p_profit

permissions:
  contents: write

env:
  PYTHONPATH: ${{ github.workspace }}

jobs:
  # First job: Parse bet types into matrix
  setup:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Set matrix
        id: set-matrix
        run: |
          BET_TYPES="${{ inputs.bet_types }}"
          # Convert comma-separated to JSON array
          JSON=$(echo "$BET_TYPES" | tr ',' '\n' | jq -R . | jq -s -c .)
          echo "matrix={\"bet_type\":$JSON}" >> $GITHUB_OUTPUT
          echo "Matrix: {\"bet_type\":$JSON}"

  # Parallel optimization jobs
  optimize:
    needs: setup
    runs-on: ubuntu-latest
    timeout-minutes: 180  # 3 hours per bet type
    strategy:
      fail-fast: false
      max-parallel: 4  # Run 4 bet types in parallel
      matrix: ${{ fromJson(needs.setup.outputs.matrix) }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3

      - name: Cache UV dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            .venv
          key: ${{ runner.os }}-uv-${{ hashFiles('uv.lock') }}
          restore-keys: |
            ${{ runner.os }}-uv-

      - name: Set up Python
        run: uv python install 3.10

      - name: Install dependencies
        run: uv sync --frozen

      - name: Download data from HF
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          OPTIMIZE_FEATURES="${{ inputs.optimize_features }}"

          # Feature optimization requires preprocessed data for regeneration
          if [ "$OPTIMIZE_FEATURES" = "true" ]; then
            echo "Feature optimization enabled - downloading preprocessed data for regeneration"
            uv run python entrypoints/download_features.py --include-preprocessed
          elif echo "$BET_TYPE" | grep -qE "corners|shots|fouls|cards"; then
            echo "Niche market detected - downloading raw match_stats too"
            uv run python entrypoints/download_features.py --include-raw
          else
            uv run python entrypoints/download_features.py
          fi

      - name: Verify features file
        run: |
          if [ ! -f "data/03-features/features_all_5leagues_with_odds.csv" ]; then
            echo "::error::Features file not found!"
            exit 1
          fi
          COLS=$(head -1 data/03-features/features_all_5leagues_with_odds.csv | tr ',' '\n' | wc -l)
          ROWS=$(wc -l < data/03-features/features_all_5leagues_with_odds.csv)
          echo "Features file: $ROWS rows, $COLS columns"

      - name: Create directories
        run: |
          mkdir -p outputs/sniper_results
          mkdir -p experiments/outputs/sniper_optimization
          mkdir -p experiments/outputs/feature_param_optimization
          mkdir -p config/feature_params
          mkdir -p models

      - name: Run feature parameter optimization for ${{ matrix.bet_type }}
        if: inputs.optimize_features == true
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          N_FEATURE_TRIALS="${{ inputs.n_feature_trials }}"

          echo "=============================================="
          echo "Feature Parameter Optimization: $BET_TYPE"
          echo "Trials: $N_FEATURE_TRIALS"
          echo "=============================================="

          uv run python experiments/run_feature_param_optimization.py \
            --bet-type "$BET_TYPE" \
            --n-trials "$N_FEATURE_TRIALS" \
            --n-folds 5 \
            --save-config \
            2>&1 | tee "outputs/feature_params_${BET_TYPE}.log"

          echo ""
          echo "=== Optimized Feature Params ==="
          if [ -f "config/feature_params/${BET_TYPE}.yaml" ]; then
            cat "config/feature_params/${BET_TYPE}.yaml"
          else
            echo "Warning: Feature params file not created"
          fi

      - name: Run sniper optimization for ${{ matrix.bet_type }}
        run: |
          BET_TYPE="${{ matrix.bet_type }}"
          N_TRIALS="${{ inputs.n_trials }}"
          WALKFORWARD="${{ inputs.walkforward }}"
          SHAP="${{ inputs.shap }}"
          OPTIMIZE_FEATURES="${{ inputs.optimize_features }}"

          echo "=============================================="
          echo "Sniper Optimization: $BET_TYPE"
          echo "Trials: $N_TRIALS"
          echo "Walk-forward: $WALKFORWARD"
          echo "SHAP Analysis: $SHAP"
          echo "Feature Params: $OPTIMIZE_FEATURES"
          echo "Auto-RFE (RFECV): ${{ inputs.auto_rfe }}"
          echo "=============================================="

          FLAGS=""
          if [ "$WALKFORWARD" = "true" ]; then
            FLAGS="$FLAGS --walkforward"
          fi
          if [ "${{ inputs.auto_rfe }}" = "true" ]; then
            FLAGS="$FLAGS --auto-rfe"
          fi
          if [ "${{ inputs.save_models }}" = "true" ]; then
            FLAGS="$FLAGS --save-models"
          fi

          # Check if feature params exist (from optimization step)
          FEATURE_PARAMS_FILE="config/feature_params/${BET_TYPE}.yaml"
          if [ "$OPTIMIZE_FEATURES" = "true" ] && [ -f "$FEATURE_PARAMS_FILE" ]; then
            echo "Using optimized feature params from: $FEATURE_PARAMS_FILE"
            # Run sniper optimization with feature params
            uv run python experiments/run_sniper_optimization.py \
              --bet-type "$BET_TYPE" \
              --n-optuna-trials "$N_TRIALS" \
              --feature-params "$FEATURE_PARAMS_FILE" \
              $FLAGS \
              --shap \
              2>&1 | tee "outputs/sniper_${BET_TYPE}.log"
          else
            # Run sniper optimization (unified pipeline)
            uv run python experiments/run_sniper_optimization.py \
              --bet-type "$BET_TYPE" \
              --n-optuna-trials "$N_TRIALS" \
              --shap \
              $FLAGS \
              2>&1 | tee "outputs/sniper_${BET_TYPE}.log"
          fi

      - name: Collect results
        if: always()
        run: |
          BET_TYPE="${{ matrix.bet_type }}"

          # Copy optimization results
          for f in experiments/outputs/*_full_optimization.json experiments/outputs/sniper_optimization/*.json; do
            if [ -f "$f" ]; then
              cp "$f" outputs/sniper_results/
              echo "Copied: $f"
            fi
          done

          # Copy feature param optimization results
          for f in experiments/outputs/feature_param_optimization/*.json; do
            if [ -f "$f" ]; then
              cp "$f" outputs/sniper_results/
              echo "Copied feature params: $f"
            fi
          done

          # Copy optimized feature params config
          if [ -f "config/feature_params/${BET_TYPE}.yaml" ]; then
            mkdir -p outputs/feature_params
            cp "config/feature_params/${BET_TYPE}.yaml" outputs/feature_params/
            echo "Copied feature config: config/feature_params/${BET_TYPE}.yaml"
          fi

          # Copy trained models
          mkdir -p outputs/models
          for f in models/${BET_TYPE}_*.joblib; do
            if [ -f "$f" ]; then
              cp "$f" outputs/models/
              echo "Copied model: $f"
            fi
          done

      - name: Upload artifacts for ${{ matrix.bet_type }}
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sniper-${{ matrix.bet_type }}-${{ github.run_number }}
          path: |
            outputs/sniper_results/
            outputs/feature_params/
            outputs/models/
            outputs/sniper_*.log
            outputs/feature_params_*.log
            experiments/outputs/*_full_optimization.json
            experiments/outputs/sniper_optimization/sniper_${{ matrix.bet_type }}_*.json
            experiments/outputs/feature_param_optimization/feature_params_${{ matrix.bet_type }}_*.json
            config/feature_params/${{ matrix.bet_type }}.yaml
            models/${{ matrix.bet_type }}_*.joblib
          retention-days: 90

  # Aggregate results from all parallel jobs
  aggregate:
    needs: optimize
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3

      - name: Set up Python
        run: uv python install 3.10

      - name: Install dependencies
        run: uv sync --frozen

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: sniper-*
          path: all-results
          merge-multiple: true

      - name: Aggregate results
        run: |
          mkdir -p outputs/final_results
          mkdir -p outputs/final_results/feature_params
          mkdir -p outputs/final_results/models

          echo "=== Downloaded artifacts structure ==="
          find all-results -type f -name "*.json" | head -30
          find all-results -type f -name "*.yaml" | head -10
          find all-results -type f -name "*.joblib" | head -20
          echo ""

          # Copy all JSON results (flatten to single directory)
          find all-results -name "*.json" -exec cp {} outputs/final_results/ \;

          # Copy all feature param YAML configs
          find all-results -name "*.yaml" -exec cp {} outputs/final_results/feature_params/ \;

          # Copy all trained models
          find all-results -name "*.joblib" -exec cp {} outputs/final_results/models/ \;
          echo "=== Trained models ==="
          ls -la outputs/final_results/models/ || echo "No models found"

          echo "=== Files in final_results ==="
          ls -la outputs/final_results/ || echo "No files found"
          echo ""
          echo "=== Feature param configs ==="
          ls -la outputs/final_results/feature_params/ || echo "No feature configs found"
          echo ""

          # Create summary
          echo "## Sniper Optimization Results" > outputs/final_results/SUMMARY.md
          echo "" >> outputs/final_results/SUMMARY.md
          echo "**Date:** $(date -u '+%Y-%m-%d %H:%M UTC')" >> outputs/final_results/SUMMARY.md
          echo "**Bet Types:** ${{ inputs.bet_types }}" >> outputs/final_results/SUMMARY.md
          echo "**Model Trials:** ${{ inputs.n_trials }}" >> outputs/final_results/SUMMARY.md
          echo "**Feature Optimization:** ${{ inputs.optimize_features }}" >> outputs/final_results/SUMMARY.md
          if [ "${{ inputs.optimize_features }}" = "true" ]; then
            echo "**Feature Trials:** ${{ inputs.n_feature_trials }}" >> outputs/final_results/SUMMARY.md
          fi
          echo "**Walk-forward:** ${{ inputs.walkforward }}" >> outputs/final_results/SUMMARY.md
          echo "" >> outputs/final_results/SUMMARY.md
          echo "| Bet Type | Model | Precision | ROI | Bets | Threshold |" >> outputs/final_results/SUMMARY.md
          echo "|----------|-------|-----------|-----|------|-----------|" >> outputs/final_results/SUMMARY.md

          # Use find to iterate over all json files (handle nested directories)
          FILE_COUNT=0
          for f in $(find outputs/final_results -name "*.json" -type f 2>/dev/null); do
            echo "Processing: $f"
            FILE_COUNT=$((FILE_COUNT + 1))
            uv run python3 -c "
          import json
          import sys

          try:
              with open('$f') as fp:
                  data = json.load(fp)

              bet_type = data.get('bet_type', 'unknown')
              model = data.get('best_model', 'N/A')
              precision = data.get('precision', 0) or 0
              roi = data.get('roi', 0) or 0
              n_bets = data.get('n_bets', 0) or 0
              threshold = data.get('best_threshold', 0) or 0

              print(f'| {bet_type} | {model} | {precision:.1%} | {roi:+.1f}% | {n_bets} | {threshold:.2f} |')
          except Exception as e:
              print(f'Error parsing $f: {e}', file=sys.stderr)
          " >> outputs/final_results/SUMMARY.md
          done

          echo ""
          echo "Processed $FILE_COUNT JSON files"
          echo "" >> outputs/final_results/SUMMARY.md

          echo "=== Final Summary ==="
          cat outputs/final_results/SUMMARY.md

      - name: Upload final results
        uses: actions/upload-artifact@v4
        with:
          name: sniper-all-results-${{ github.run_number }}
          path: outputs/final_results/
          retention-days: 90

      - name: Generate deployment config
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          # Generate deployment config from optimization results
          # With --only-if-better, it downloads current config and compares
          FLAGS=""
          if [ "${{ inputs.only_if_better }}" = "true" ]; then
            FLAGS="--only-if-better --metric ${{ inputs.comparison_metric }}"
          fi

          uv run python scripts/generate_deployment_config.py \
            --source outputs/final_results \
            --output config/sniper_deployment.json \
            $FLAGS

          echo ""
          echo "=== Deployment Config ==="
          cat config/sniper_deployment.json | head -80

      - name: Upload to HF Hub
        if: inputs.upload_results == true
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          uv run python -c "
          from huggingface_hub import HfApi
          import os
          from pathlib import Path
          from datetime import datetime

          api = HfApi()
          token = os.environ.get('HF_TOKEN')

          if not token:
              print('No HF_TOKEN found, skipping upload')
              exit(0)

          results_dir = Path('outputs/final_results')
          if not results_dir.exists():
              print('No results to upload')
              exit(0)

          timestamp = datetime.now().strftime('%Y%m%d_%H%M')

          # Upload optimization results
          for f in results_dir.glob('*.json'):
              try:
                  api.upload_file(
                      path_or_fileobj=str(f),
                      path_in_repo=f'sniper_optimization/{timestamp}/{f.name}',
                      repo_id='czlowiekZplanety/bettip-data',
                      repo_type='dataset',
                      token=token
                  )
                  print(f'Uploaded: {f.name}')
              except Exception as e:
                  print(f'Failed to upload {f.name}: {e}')

          # Upload feature param configs
          feature_params_dir = results_dir / 'feature_params'
          if feature_params_dir.exists():
              for f in feature_params_dir.glob('*.yaml'):
                  try:
                      api.upload_file(
                          path_or_fileobj=str(f),
                          path_in_repo=f'config/feature_params/{f.name}',
                          repo_id='czlowiekZplanety/bettip-data',
                          repo_type='dataset',
                          token=token
                      )
                      print(f'Uploaded feature params: {f.name}')
                  except Exception as e:
                      print(f'Failed to upload {f.name}: {e}')

          # Upload trained models
          models_dir = results_dir / 'models'
          if models_dir.exists():
              for f in models_dir.glob('*.joblib'):
                  try:
                      api.upload_file(
                          path_or_fileobj=str(f),
                          path_in_repo=f'models/{f.name}',
                          repo_id='czlowiekZplanety/bettip-data',
                          repo_type='dataset',
                          token=token
                      )
                      print(f'Uploaded model: {f.name}')
                  except Exception as e:
                      print(f'Failed to upload {f.name}: {e}')

          # Upload deployment config
          config_path = Path('config/sniper_deployment.json')
          if config_path.exists():
              try:
                  api.upload_file(
                      path_or_fileobj=str(config_path),
                      path_in_repo='config/sniper_deployment.json',
                      repo_id='czlowiekZplanety/bettip-data',
                      repo_type='dataset',
                      token=token
                  )
                  print('Uploaded deployment config')
              except Exception as e:
                  print(f'Failed to upload config: {e}')
          "

      - name: Create job summary
        if: always()
        run: |
          echo "## Sniper Optimization Pipeline (Parallel)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Configuration" >> $GITHUB_STEP_SUMMARY
          echo "| Parameter | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Bet Types | \`${{ inputs.bet_types }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Model Trials | ${{ inputs.n_trials }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Feature Optimization | ${{ inputs.optimize_features }} |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ inputs.optimize_features }}" = "true" ]; then
            echo "| Feature Trials | ${{ inputs.n_feature_trials }} |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "| Walk-Forward | ${{ inputs.walkforward }} |" >> $GITHUB_STEP_SUMMARY
          echo "| SHAP Analysis | ${{ inputs.shap }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Only If Better | ${{ inputs.only_if_better }} |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ inputs.only_if_better }}" = "true" ]; then
            echo "| Comparison Metric | ${{ inputs.comparison_metric }} |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f "outputs/final_results/SUMMARY.md" ]; then
            echo "### Results" >> $GITHUB_STEP_SUMMARY
            cat outputs/final_results/SUMMARY.md >> $GITHUB_STEP_SUMMARY
          fi

          # Show optimized feature params if available
          if [ -d "outputs/final_results/feature_params" ] && [ "$(ls -A outputs/final_results/feature_params 2>/dev/null)" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Optimized Feature Parameters" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            for f in outputs/final_results/feature_params/*.yaml; do
              if [ -f "$f" ]; then
                BET_TYPE=$(basename "$f" .yaml)
                echo "<details><summary>$BET_TYPE</summary>" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`yaml" >> $GITHUB_STEP_SUMMARY
                cat "$f" >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                echo "</details>" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
              fi
            done
          fi
