name: Data Pipeline - Collect & Process

on:
  schedule:
    - cron: '0 3 * * 1'

  workflow_dispatch:
    inputs:
      days_back:
        description: 'number of days back to download'
        required: false
        default: '10'
        type: string
      season:
        description: 'season (year of start)'
        required: false
        default: '2025'
        type: string

permissions:
  contents: write

jobs:
  collect-data:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install uv
        uses: astral-sh/setup-uv@v3

      - name: Set up Python
        run: uv python install 3.10

      - name: Install dependencies
        run: uv sync --frozen

      - name: Create .env file with API key
        run: |
          echo "API_FOOTBALL_KEY=${{ secrets.API_FOOTBALL_KEY }}" > .env
          echo "API_BASE_URL=${{ vars.API_BASE_URL }}" >> .env
          echo "DAILY_LIMIT=${{ vars.DAILY_LIMIT }}" >> .env
          echo "PER_MIN_LIMIT=${{ vars.PER_MIN_LIMIT }}" >> .env
          echo "STATE_PATH=${{ vars.STATE_PATH }}" >> .env

      - name: Create data directories
        run: |
          mkdir -p data/01-raw
          mkdir -p data/02-preprocessed
          mkdir -p data/03-features

      - name: Run match collector
        run: |
          DAYS_BACK="${{ github.event.inputs.days_back || '26' }}"
          SEASON="${{ github.event.inputs.season || '2025' }}"

          echo "Download data for season $SEASON, last $DAYS_BACK days..."
          uv run python entrypoints/collect.py \
            --mode update \
            --strategy smart \
            --season $SEASON \
            --days-back $DAYS_BACK

      - name: Preprocess data
        if: success()
        run: |
          SEASON="${{ github.event.inputs.season || '2025' }}"
          echo "Preprocessing data for season $SEASON..."
          uv run python entrypoints/preprocess.py \
            --config config/local.yaml \
            --seasons $SEASON

      - name: Generate features
        if: success()
        run: |
          SEASON="${{ github.event.inputs.season || '2025' }}"
          echo "Generating features for season $SEASON..."
          uv run python entrypoints/features.py \
            --config config/local.yaml \
            --seasons $SEASON

      - name: Prepare data for commit
        id: check_changes
        run: |
          if [ -n "$(git status --porcelain data/)" ]; then
            echo "has_changes=true" >> $GITHUB_OUTPUT
            echo "Found new data in data directories"
          else
            echo "has_changes=false" >> $GITHUB_OUTPUT
            echo "No new data"
          fi

      - name: Configure Git
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Switch to data branch
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          # Save updated data to temp location
          cp -r data /tmp/updated-data

          if git ls-remote --heads origin data | grep -q data; then
            echo "Branch 'data' exist, checkout..."
            git fetch origin data
            git switch data 2>/dev/null || git checkout -t origin/data
          else
            echo "create new data branch 'data'..."
            git checkout --orphan data
            git rm -rf . 2>/dev/null || true
          fi

          # Restore updated data from temp
          cp -r /tmp/updated-data data

      - name: Commit and push data
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          SEASON="${{ github.event.inputs.season || '2025' }}"

          git add -f data/01-raw/*/$SEASON/fixtures.json

          FILE_COUNT=$(git diff --cached --numstat | wc -l)
          TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M:%S UTC")

          if [ "$FILE_COUNT" -eq "0" ]; then
            echo "No specific files to commit."
            exit 0
          fi

          git commit -m "Update fixtures for season $SEASON - $TIMESTAMP" \
                     -m "Files updated: $FILE_COUNT"

          git push origin data

      - name: Create summary
        if: always()
        run: |
          echo "## Data Collection & Processing Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ steps.check_changes.outputs.has_changes }}" == "true" ]; then
            echo "âœ… Data updated and saved in branch 'data'" >> $GITHUB_STEP_SUMMARY
          else
            echo "â„¹ï¸ No new data to save" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Pipeline Steps" >> $GITHUB_STEP_SUMMARY
          echo "1. ðŸ“¥ **Collect** - Smart update of match data" >> $GITHUB_STEP_SUMMARY
          echo "2. ðŸ”„ **Preprocess** - Transform JSON to Parquet" >> $GITHUB_STEP_SUMMARY
          echo "3. ðŸŽ¯ **Features** - Generate ML-ready features" >> $GITHUB_STEP_SUMMARY

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Parameters" >> $GITHUB_STEP_SUMMARY
          echo "- **Season**: ${{ github.event.inputs.season || '2025' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Days back**: ${{ github.event.inputs.days_back || '26' }}" >> $GITHUB_STEP_SUMMARY

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Data Directories" >> $GITHUB_STEP_SUMMARY
          echo "- \`data/01-raw/\` - Raw JSON from API" >> $GITHUB_STEP_SUMMARY
          echo "- \`data/02-preprocessed/\` - Cleaned Parquet files" >> $GITHUB_STEP_SUMMARY
          echo "- \`data/03-features/\` - ML features (CSV)" >> $GITHUB_STEP_SUMMARY

          if [ -f fixtures_updater.log ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Last log lines" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            tail -20 fixtures_updater.log >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload logs as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: collector-logs
          path: |
            fixtures_updater.log
            state.json
          retention-days: 30